{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "> **Copyright &copy; 2020 CertifAI Sdn. Bhd.**<br>\n",
    " **Copyright &copy; 2021 CertifAI Sdn. Bhd.**<br>\n",
    " <br>\n",
    "This program and the accompanying materials are made available under the\n",
    "terms of the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \\\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n",
    "WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n",
    "License for the specific language governing permissions and limitations\n",
    "under the License. <br>\n",
    "<br>**SPDX-License-Identifier: Apache-2.0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is to demonstrate the process in build LSTM for the Univariate Time Series Data,<br>\n",
    "It consists of 2 major part which are :\n",
    "\n",
    "1. The Demostration of Building LSTM using Synthetic data \n",
    "2. Exercise of building LSTM using shampoo sales data.\n",
    "\n",
    "First, we will show the step in building the LSTM : \n",
    "\n",
    "Step 1. Data Preparation (Data Splitting,Data Sequencing,Data Normalization and Batching the Data)<br>\n",
    "Step 2. Model Configuration (Vanila LSTM , Stacked LSTM , Bidirectional LSTM)<br>\n",
    "Step 3. Train the model <br>\n",
    "Step 4. Validate the model using graph <br>\n",
    "Step 5. Evaluation Metrics such as MSE <br>\n",
    "Step 6. Plot the forecast result\n",
    "\n",
    "First , let's us import the package needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data sequencing function \n",
    "def univariate_single_step(sequence, window_size):\n",
    "    x, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "    # find the end of this pattern\n",
    "        end_ix = i + window_size\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "    # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(x), np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter\n",
    "Define the hyper parameter that need to tune the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e5e0fc6eb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_ratio = 0.70\n",
    "num_epochs = 800\n",
    "window_size = 2\n",
    "batch_size = 10\n",
    "#seed\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "We create synthetic data to make sure the model is created correctly and having ability to perform the forecasting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0,  10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120,\n",
       "       130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250,\n",
       "       260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380,\n",
       "       390])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Synthetic Data\n",
    "univariate_series = np.array([x for x in range(0, 400, 10)])\n",
    "print(univariate_series.shape)\n",
    "univariate_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data = round(len(univariate_series)*split_ratio)\n",
    "split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_shape\n",
      "(28,)\n",
      "test_data_shape\n",
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "#split data by indexing \n",
    "train_data = univariate_series[:split_data]\n",
    "test_data = univariate_series[split_data:]\n",
    "print(\"train_data_shape\")\n",
    "print(train_data.shape)\n",
    "print(\"test_data_shape\")\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Standardization\n",
    "Standardize your numeric attributes to have a 0 mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the standard scaler, Use to fit the train data and take the statistic of train data apply in test data\n",
    "scaler = StandardScaler().fit(train_data.reshape(-1, 1))\n",
    "train_data_standard = scaler.transform(train_data.reshape(-1, 1))\n",
    "test_data_standard = scaler.transform(test_data.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sequencing\n",
    "Sequencing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape:(26, 2, 1) trainY shape:(26, 1)\n",
      "\n",
      "testX shape:(10, 2, 1) testX shape:(10, 1)\n"
     ]
    }
   ],
   "source": [
    "trainX ,trainY =  univariate_single_step(train_data_standard,window_size)\n",
    "testX , testY = univariate_single_step(test_data_standard,window_size)\n",
    "print(f\"trainX shape:{trainX.shape} trainY shape:{trainY.shape}\\n\")\n",
    "print(f\"testX shape:{testX.shape} testX shape:{testY.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transform\n",
    "Data need to transform from numpy to pytorch tensor before feed into the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape:torch.Size([26, 2, 1]) trainY shape:torch.Size([26, 1])\n",
      "\n",
      "testX shape:torch.Size([10, 2, 1]) testY shape:torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "#transfrom to Pytorch tensor\n",
    "trainX = torch.from_numpy(trainX).type(torch.Tensor)\n",
    "trainY = torch.from_numpy(trainY).type(torch.Tensor)\n",
    "testX = torch.from_numpy(testX).type(torch.Tensor)\n",
    "testY = torch.from_numpy(testY).type(torch.Tensor)\n",
    "print(f\"trainX shape:{trainX.shape} trainY shape:{trainY.shape}\\n\")\n",
    "print(f\"testX shape:{testX.shape} testY shape:{testY.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features are now in the shape of torch.Size([26, 2, 1]) while labels are now in the shape of torch.Size([26, 1])\n",
      "\n",
      "x-feature\n",
      "26 = total number of data \n",
      "2 = window size \n",
      "1 = number of time series\n",
      "\n",
      "y-label\n",
      "26 = number of data\n",
      "1 = number of step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Display the shape to make sure the transform is success\n",
    "print(f\"Features are now in the shape of {trainX.shape} while labels are now in the shape of {trainY.shape}\\n\")\n",
    "print(\"x-feature\\n\"+str(trainX.shape[0])+\" = total number of data \")\n",
    "print(str(trainX.shape[1])+\" = window size \")\n",
    "print(str(trainX.shape[2])+\" = number of time series\\n\")\n",
    "print(\"y-label\\n\"+str(trainY.shape[0])+\" = number of data\")\n",
    "print(str(trainY.shape[1])+\" = number of step\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Iterator\n",
    "Iterator is create to allow the data separate into several batches to fasten the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Iterator\n",
    "train_dataset = TensorDataset(trainX, trainY)\n",
    "train_iter = DataLoader(train_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(testX, testY)\n",
    "test_iter = DataLoader(test_dataset,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model Configuration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanila LSTM\n",
    "\n",
    "The method use to create the model is call pytorch subclass method. It consists of 2 part where the first part is allow user to define the structure of the model such as the **number of input unit**, **number of output unit** and **number of hidden unit** as well. \n",
    "\n",
    "Second part of the method consist of forward() method , it allow user to control the flow of input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "        def __init__(self, n_feature, hidden_dim, num_layers, output_dim):\n",
    "            super(LSTM, self).__init__()\n",
    "\n",
    "            self.n_feature = n_feature\n",
    "            # Hidden dimensions\n",
    "            self.hidden_dim = hidden_dim\n",
    "\n",
    "            # Number of hidden layers\n",
    "            self.num_layers = num_layers\n",
    "\n",
    "            # Building your LSTM\n",
    "            # batch_first=True causes input/output tensors to be of shape\n",
    "            # (batch_dim, seq_dim, feature_dim)\n",
    "            self.lstm = nn.LSTM(n_feature, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "            # Readout layer\n",
    "            self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            # Initialize hidden state with zeros\n",
    "            h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim)\n",
    "\n",
    "            # Initialize cell state with zeros\n",
    "            c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim)\n",
    "\n",
    "            # One time step\n",
    "            # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "            # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "            out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "            # Index hidden state of last time step\n",
    "            # just want last time step hidden states!\n",
    "            out = self.fc(out[:, -1, :])\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM\n",
    "The only different in the configuration of Bidirectional LSTM and Vanila LSTM is the number of layer need be multiplication of  2 or *2. For example : \n",
    "\n",
    "self.fc = nn.Linear(hidden_dim *2, output_dim) <br>\n",
    "h0 = torch.zeros(self.num_layers *2, x.size(0), self.hidden_dim)<br>\n",
    "c0 = torch.zeros(self.num_layers *2, x.size(0), self.hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionalLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, n_feature, hidden_dim, num_layers, output_dim):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "\n",
    "        self.n_feature = n_feature\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Building your LSTM\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(n_feature, hidden_dim, num_layers, batch_first=True,bidirectional=True)\n",
    "\n",
    "        # Readout layer *2 for bidirectional LSTM\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_dim)\n",
    "\n",
    "        # Initialize cell state with zeros\n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_dim)\n",
    "\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Model \n",
    "The model is input by feed in the require attributes such as number of input layer, output layer and hidden layer.\n",
    "\n",
    "How to Use : \n",
    "1. Select one of the model base on the application as below and comment others model\n",
    "2. IF use Vanila LSTM , set num_layer = 1 and use the model = LSTM()\n",
    "3. IF use stacked LSTM , set num_layer more than 1 and use the model = LSTM()\n",
    "4. IF use Bidirectional LSTM, use the  model = BidirectionalLSTM()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arguments for LSTM model\n",
    "hidden_dim = 100\n",
    "number_of_time_series = 1 \n",
    "timestep = 1 \n",
    "\n",
    "#1 for vanila LSTM , >1 is mean stacked LSTM\n",
    "num_layers = 3 \n",
    "\n",
    "#Vanila , Stacked LSTM\n",
    "model = LSTM(n_feature=number_of_time_series, hidden_dim=hidden_dim, output_dim=timestep, num_layers=num_layers)\n",
    "\n",
    "#Bidirectional LSTM\n",
    "# model = BidirectionalLSTM(n_feature=number_of_time_series, hidden_dim=hidden_dim, output_dim=timestep, num_layers=num_layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the MSE as loss function and using Adam as the model optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function \n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "#optimiser\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(num_epochs,train_iter,test_iter,optimiser,loss_fn,model):\n",
    "    # Create a list of zero value to store the averaged value\n",
    "    train_loss = np.zeros(num_epochs)\n",
    "    val_loss = np.zeros(num_epochs)\n",
    "    \n",
    "    # For loop to loop through the data iterator\n",
    "    for t in range(num_epochs):\n",
    "        \n",
    "        # Initial the value to be zero to perform cummulative sum \n",
    "        running_loss_train = 0\n",
    "        running_loss_valid = 0\n",
    "        \n",
    "        for _,(train_X,train_Y) in enumerate(train_iter):\n",
    "\n",
    "            # Forward pass\n",
    "            y_train_pred = model(train_X)\n",
    "\n",
    "            # Reshape to ensure the predicted output (y_train_pred) same size with train_Y shape\n",
    "            y_train_pred=torch.reshape(y_train_pred,(train_Y.shape[0],train_Y.shape[1]))\n",
    "            \n",
    "            #Compare the value using MSE\n",
    "            loss_train = loss_fn(y_train_pred, train_Y)\n",
    "\n",
    "            # Zero out gradient, else they will accumulate between epochs\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            # Backward pass\n",
    "            loss_train.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimiser.step()\n",
    "            \n",
    "            # Summing up the loss over each epoch\n",
    "            running_loss_train += loss_train.item()\n",
    "            \n",
    "        # Average the loss base of the batch size \n",
    "        epoch_loss_train = running_loss_train /len(train_X)\n",
    "        \n",
    "        # Store the averaged value\n",
    "        train_loss[t] = epoch_loss_train\n",
    "        \n",
    "        # Validate the test data loss\n",
    "        with torch.no_grad():\n",
    "            for _,(test_X,test_Y) in enumerate(test_iter):\n",
    "                y_test_pred = model(test_X)\n",
    "\n",
    "                # Reshape to ensure the predicted output (y_test_pred) same size with test_y shape\n",
    "                y_test_pred=torch.reshape(y_test_pred,(test_Y.shape[0],test_Y.shape[1]))\n",
    "                \n",
    "                # Calculate the loss \n",
    "                loss_test = loss_fn(y_test_pred, test_Y)\n",
    "                \n",
    "                # Summing up the loss over each epoch\n",
    "                running_loss_valid += loss_test.item()\n",
    "                \n",
    "        # Average the loss base of the batch size \n",
    "        epoch_loss_test =running_loss_valid /len(test_X)\n",
    "        \n",
    "        # Store the averaged value\n",
    "        val_loss[t] = epoch_loss_test\n",
    "    \n",
    "    return train_loss,val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Training \n",
    "train_loss,val_loss = training(num_epochs,train_iter,test_iter,optimiser,loss_fn,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation \n",
    "A train loss and val loss is plotted to define how well the data is fitting the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(train_loss, label=\"Training\")\n",
    "plt.plot(val_loss, label=\"Testing\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.title(\"Train Loss & Test Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e5e3c7d550>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Zoom in by fill in start_epoch and end_epoch\n",
    "start_epoch = 790\n",
    "end_epoch = 800\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(train_loss[start_epoch:end_epoch], label=\"Training loss\")\n",
    "plt.plot(val_loss[start_epoch:end_epoch], label=\"Testing loss\")\n",
    "plt.title(\"Losses\")\n",
    "plt.xlabel(\"Epoch_Demand\")\n",
    "plt.ylabel(\"MSE_Demand\")\n",
    "position=range(end_epoch-start_epoch)\n",
    "labels=range(start_epoch,end_epoch)\n",
    "plt.xticks(position, labels)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "This section is to inference the model by feeding in testing data and determine the output forecast value and calculate the RMSE .\n",
    "\n",
    "It consist of 4 section :\n",
    "\n",
    "Section 1 : Feed in the train and test data to the model <br>\n",
    "Section 2 : Reshape both to the original data dimension <br>\n",
    "Section 3 : Invert the scaling back to orignal data value <br>\n",
    "Section 4 : Calculate the RMSE of train and test data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1 : make predictions\n",
    "with torch.no_grad():\n",
    "    y_train_prediction = model(trainX)\n",
    "    y_test_prediction = model(testX)\n",
    "\n",
    "# Section 2 : Reshape to original data\n",
    "y_train_prediction= torch.reshape(y_train_prediction,(y_train_prediction.shape[0],y_train_prediction.shape[1]))\n",
    "trainY = torch.reshape(trainY,(trainY.shape[0],trainY.shape[1]))\n",
    "y_test_prediction = torch.reshape(y_test_prediction,(y_test_prediction.shape[0],y_test_prediction.shape[1]))\n",
    "testY = torch.reshape(testY,(testY.shape[0],testY.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3 : Invert predictions\n",
    "y_train_prediction= scaler.inverse_transform(y_train_prediction.detach().numpy())\n",
    "y_train = scaler.inverse_transform(trainY.detach().numpy())\n",
    "y_test_prediction = scaler.inverse_transform(y_test_prediction.detach().numpy())\n",
    "y_test = scaler.inverse_transform(testY.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data\t\t\tForecast Data\n",
      "[300.]\t\t[296.5504]\n",
      "[310.]\t\t[304.9171]\n",
      "[320.]\t\t[312.9347]\n",
      "[330.]\t\t[320.59573]\n",
      "[340.]\t\t[327.89822]\n",
      "[350.]\t\t[334.8449]\n",
      "[360.]\t\t[341.44238]\n",
      "[370.]\t\t[347.7002]\n",
      "[380.]\t\t[353.63007]\n",
      "[390.]\t\t[359.2453]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Data\\t\\t\\tForecast Data\")\n",
    "for i in range(len(y_test_prediction)):\n",
    "    print(f\"{y_test[i]}\\t\\t{y_test_prediction[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test_shape : (10, 1)\n",
      "y_test_pred_shape : (10, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_test_shape : {y_test.shape}\")\n",
    "print(f\"y_test_pred_shape : {y_test_prediction.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.24 RMSE\n",
      "Test Score: 17.42 RMSE\n"
     ]
    }
   ],
   "source": [
    "# Section 4 : Calculate root mean squared error for both train and test data \n",
    "trainScore = math.sqrt(mean_squared_error(y_train[:,0], y_train_prediction[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(y_test[:,0], y_test_prediction[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise for Univariate (Solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task : Using LSTM to create a model that can predict lastest sales of shampoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e5e0fc6eb0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter\n",
    "num_epochs_shampoo = 39\n",
    "split_ratio = 0.70\n",
    "batch_size_shampoo = 5\n",
    "window_size_shampoo = 2\n",
    "\n",
    "#Hidden Layer for LSTM\n",
    "hidden_dim = 32\n",
    "\n",
    "#seed\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    266.0\n",
       "1    145.9\n",
       "2    183.1\n",
       "3    119.3\n",
       "4    180.3\n",
       "Name: sales, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shampoo = pd.read_csv('../../datasets/others/shampoo-sales.csv')\n",
    "shampoo_ts =shampoo['sales']\n",
    "shampoo_ts.head() \n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data by indexing \n",
    "split_data = round(len(shampoo_ts)*split_ratio)\n",
    "split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_shampoo_shape\n",
      "(25,)\n",
      "test_data_shampoo_shape\n",
      "(11,)\n"
     ]
    }
   ],
   "source": [
    "# Visualize data shape after splitting\n",
    "train_data_shampoo = shampoo_ts[:split_data]\n",
    "test_data_shampoo = shampoo_ts[split_data:]\n",
    "train_time = shampoo_ts.index[:split_data]\n",
    "test_time = shampoo_ts.index[split_data:]\n",
    "print(\"train_data_shampoo_shape\")\n",
    "print(train_data_shampoo.shape)\n",
    "print(\"test_data_shampoo_shape\")\n",
    "print(test_data_shampoo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MinMaxScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-303829621deb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Build Scaler and scale the train and test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtrain_data_normalized_shampoo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_shampoo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtest_data_normalized_shampoo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data_shampoo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MinMaxScaler' is not defined"
     ]
    }
   ],
   "source": [
    "# Reshape before normalize\n",
    "train_data_shampoo = train_data_shampoo.values.reshape(-1, 1)\n",
    "test_data_shampoo = test_data_shampoo.values.reshape((-1, 1))\n",
    "\n",
    "# Build Scaler and scale the train and test data\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_data_normalized_shampoo = scaler.fit_transform(train_data_shampoo)\n",
    "test_data_normalized_shampoo = scaler.fit_transform(test_data_shampoo)\n",
    "train_data_normalized_shampoo[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sequencing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_shampoo ,trainY_shampoo =  univariate_single_step(train_data_normalized_shampoo,window_size_shampoo)\n",
    "testX_shampoo , testY_shampoo = univariate_single_step(test_data_normalized_shampoo,window_size_shampoo)\n",
    "print(f\"trainX shape:{trainX_shampoo.shape} trainY shape:{trainY_shampoo.shape}\\n\")\n",
    "print(f\"testX shape:{testX_shampoo.shape} testX shape:{testY_shampoo.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfrom numpy to Pytorch tensor\n",
    "# Make training and test sets in torch\n",
    "trainX_shampoo = torch.from_numpy(trainX_shampoo).type(torch.Tensor)\n",
    "trainY_shampoo = torch.from_numpy(trainY_shampoo).type(torch.Tensor)\n",
    "testX_shampoo = torch.from_numpy(testX_shampoo).type(torch.Tensor)\n",
    "testY_shampoo = torch.from_numpy(testY_shampoo).type(torch.Tensor)\n",
    "print(f\"trainX shape:{trainX_shampoo.shape} trainY shape:{trainY_shampoo.shape}\\n\")\n",
    "print(f\"testX shape:{testX_shampoo.shape} testX shape:{testY_shampoo.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Iterator\n",
    "train_dataset_shampoo = TensorDataset(trainX_shampoo, trainY_shampoo)\n",
    "train_iter_shampoo = DataLoader(train_dataset_shampoo,batch_size=batch_size_shampoo,shuffle=False)\n",
    "\n",
    "test_dataset_shampoo = TensorDataset(testX_shampoo, testY_shampoo)\n",
    "test_iter_shampoo = DataLoader(test_dataset_shampoo,batch_size=batch_size_shampoo,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Model \n",
    "\n",
    "The model is input by feed in the require attributes such as number of input layer, output layer and hidden layer.\n",
    "\n",
    "How to Use :\n",
    "\n",
    "1. Select one of the model base on the application as below and comment others model\n",
    "2. IF use Vanila LSTM , set num_layer = 1 and use the model = LSTM()\n",
    "3. IF use stacked LSTM , set num_layer more that 1 and use the model = LSTM()\n",
    "4. IF use Bidirectional LSTM,use the model = BidirectionalLSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for LSTM model\n",
    "number_of_time_series = 1 \n",
    "timestep = 1\n",
    "output_dim =1 \n",
    "\n",
    "# num_layers : 1 for vanila LSTM , >1 is mean stacked LSTM\n",
    "num_layers = 3\n",
    "\n",
    "# Vanila ,Stacked LSTM\n",
    "# model_shampoo = LSTM(n_feature=number_of_time_series, hidden_dim=hidden_dim, output_dim=timestep, num_layers=num_layers)\n",
    "\n",
    "# Bidirectional LSTM\n",
    "model_shampoo = BidirectionalLSTM(n_feature=number_of_time_series, hidden_dim=hidden_dim, output_dim=timestep, num_layers=num_layers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MSE as Loss function \n",
    "loss_fn_shampoo = torch.nn.MSELoss()\n",
    "\n",
    "# Set up optimiser \n",
    "optimiser_shampoo = torch.optim.Adam(model_shampoo.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Training \n",
    "train_loss_shampoo,val_loss_shampoo = training(num_epochs_shampoo,train_iter_shampoo,test_iter_shampoo,optimiser_shampoo,loss_fn_shampoo,model_shampoo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "The first part is plot the Train loss & Test loss as the training goes on \n",
    "\n",
    "The second part serve as a function to zoom in certain period on Train loss & Test loss graph to have a clear visualize cause sometime the loss will skew and make us hard to determine the best fit epoch .\n",
    "\n",
    "For example : The learning curve is skew heavily on the left ,the remaining losses is hard to visualize\n",
    "<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-A-Good-Fit.png\" width =\"500\" height=500 >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Learning Curve \n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(train_loss_shampoo, label=\"Training loss\")\n",
    "plt.plot(val_loss_shampoo, label=\"Testing loss\")\n",
    "plt.xlabel(\"Epoch_shampoo\")\n",
    "plt.ylabel(\"MSE_shampoo\")\n",
    "plt.legend()\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom in to visualize the graph by fill in start_epoch and end_epoch that want to analyse\n",
    "start_epoch = 35\n",
    "end_epoch = 40\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(train_loss_shampoo[start_epoch:end_epoch], label=\"Training loss\")\n",
    "plt.plot(val_loss_shampoo[start_epoch:end_epoch], label=\"Testing loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Epoch_Demand\")\n",
    "plt.ylabel(\"MSE_Demand\")\n",
    "position=range(end_epoch-start_epoch)\n",
    "labels=range(start_epoch,end_epoch)\n",
    "plt.xticks(position, labels)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "This section is to inference the model and plot the forecast result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    y_train_prediction_shampoo= model_shampoo(trainX_shampoo)\n",
    "    y_test_prediction_shampoo= model_shampoo(testX_shampoo)\n",
    "\n",
    "# Reshape to original data\n",
    "y_train_prediction_shampoo = torch.reshape(y_train_prediction_shampoo,(y_train_prediction_shampoo.shape[0],y_train_prediction_shampoo.shape[1]))\n",
    "trainY_shampoo = torch.reshape(trainY_shampoo,(trainY_shampoo.shape[0],trainY_shampoo.shape[1]))\n",
    "y_test_prediction_shampoo = torch.reshape(y_test_prediction_shampoo,(y_test_prediction_shampoo.shape[0],y_test_prediction_shampoo.shape[1]))\n",
    "testY_shampoo = torch.reshape(testY_shampoo,(testY_shampoo.shape[0],testY_shampoo.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert predictions\n",
    "y_train_pred_shampoo = scaler.inverse_transform(y_train_prediction_shampoo.detach().numpy())\n",
    "y_train_shampoo = scaler.inverse_transform(trainY_shampoo.detach().numpy())\n",
    "y_test_pred_shampoo = scaler.inverse_transform(y_test_prediction_shampoo.detach().numpy())\n",
    "y_test_shampoo = scaler.inverse_transform(testY_shampoo.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y-test\\t\\ty-predict\")\n",
    "for i in range(len(y_test_shampoo)):\n",
    "    print(f\"{y_test_shampoo[i]}\\t\\t{y_test_pred_shampoo[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"y_test_shape : {y_test_shampoo.shape}\")   \n",
    "print(f\"y_test_pred_shape : {y_test_pred_shampoo.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate root mean squared error\n",
    "trainScore_shampoo = math.sqrt(mean_squared_error(y_train_shampoo[:,0], y_train_pred_shampoo[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore_shampoo))\n",
    "testScore_shampoo = math.sqrt(mean_squared_error(y_test_shampoo[:,0], y_test_pred_shampoo[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore_shampoo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjustment to make the sequence data plot on original test data \n",
    "a=range(split_data+window_size_shampoo,split_data+len(y_test_shampoo)+window_size_shampoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(test_time,test_data_shampoo, label = 'Test Data')\n",
    "plt.plot(a,y_test_shampoo, color=\"green\",label = 'Test Data After Sequencing')\n",
    "plt.plot(a,y_test_pred_shampoo,color=\"red\", label = 'Forecast')\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Shampoo Sales\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "1. Deep Learning for Time Series Forecasting (Predict the Future with MLPs,CNNs and LSTMs in Python) , Jason Brownlee"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
