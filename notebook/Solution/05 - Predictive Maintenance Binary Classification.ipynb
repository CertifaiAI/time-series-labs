{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "> **Copyright &copy; 2020 CertifAI Sdn. Bhd.**<br>\n",
    " **Copyright &copy; 2021 CertifAI Sdn. Bhd.**<br>\n",
    " <br>\n",
    "This program and the accompanying materials are made available under the\n",
    "terms of the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \\\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n",
    "WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n",
    "License for the specific language governing permissions and limitations\n",
    "under the License. <br>\n",
    "<br>**SPDX-License-Identifier: Apache-2.0**> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 05 - Predictive Maintenance Binary Classification\n",
    " Predictive maintenance techniques are designed to help determine the condition of in-service equipment in order to\n",
    " estimate when maintenance should be performed. Predictive maintenance can be modeled in several ways,\n",
    " 1. Predict the Remaining Useful Life (RUL), or Time to Failure (TTF)\n",
    " 2. Predict if the asset will fail by given a certain time frame\n",
    " 3. Predict critical level of the asset by give a certain time frame\n",
    "\n",
    " This example we will look at the 2nd modeling strategy which is to predict weather the asset is going to fail. The target variable is \"Label1\".\n",
    " This label consist of 0 and 1. 0 means the assets is working fine and 1 means it require maintenance."
   ]
  },
  {
   "source": [
    "## Notebook Description\n",
    "This tutorial will show different approaches other than deep learning that can be applied to search for anomalies. All the techniques is readily available in Scikit-learn library. An exercise section is attached for you to practice and hone your skills. Do make good use of it.\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "1. Prepare dataset to be feed into anomaly detection algorithms\n",
    "2. Apply different anomaly detection algorithms readily accessible from Scikit-learn API\n",
    "3. Compare and contrast performance of anomaly detection algorithms\n",
    "\n",
    "## Notebook Outline\n",
    "Below is the outline for this tutorial:\n",
    "1. [A Little Bit of Theory](#theory)\n",
    "2. [Choice of Dataset](#dataset)\n",
    "3. [Baseline Performance](#baseline)\n",
    "4. [Anomaly Detection Techniques](#techniques) \n",
    "    * a) [Isolation Forest](#isolation-forest)\n",
    "    * b) [Minimum Covariance Determinant](#minimum-cov-determinant)\n",
    "    * c) [Local Outlier Factor (LOF)](#lof)\n",
    "    * d) [One-class Support Vector Machine (OCSVM)](#ocsvm)\n",
    "\n",
    "5. [Exercise](#exercise)\n",
    "6. [Reference](#reference)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sys\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, IterableDataset\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading dataset\n",
    "df_train = pd.read_csv(\"../../datasets/predictive_maintenance/train.csv\")\n",
    "df_test = pd.read_csv(\"../../datasets/predictive_maintenance/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>s10</th>\n",
       "      <th>s11</th>\n",
       "      <th>s12</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>cycle_norm</th>\n",
       "      <th>RUL</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.726248</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.109755</td>\n",
       "      <td>0</td>\n",
       "      <td>0.369048</td>\n",
       "      <td>0.633262</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.199608</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.724662</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.628019</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.100242</td>\n",
       "      <td>0</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.765458</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.162813</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731014</td>\n",
       "      <td>0.00277</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.140043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.795309</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.171793</td>\n",
       "      <td>0.357445</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.621375</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.124518</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.889126</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.174889</td>\n",
       "      <td>0.166603</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>0.00831</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.668277</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.149960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.255952</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.174734</td>\n",
       "      <td>0.402078</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.704502</td>\n",
       "      <td>0.01108</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3  s1        s2        s3        s4  \\\n",
       "0   1      1  0.459770  0.166667         0   0  0.183735  0.406802  0.309757   \n",
       "1   1      2  0.609195  0.250000         0   0  0.283133  0.453019  0.352633   \n",
       "2   1      3  0.252874  0.750000         0   0  0.343373  0.369523  0.370527   \n",
       "3   1      4  0.540230  0.500000         0   0  0.343373  0.256159  0.331195   \n",
       "4   1      5  0.390805  0.333333         0   0  0.349398  0.257467  0.404625   \n",
       "\n",
       "   s5  s6        s7        s8        s9  s10       s11       s12       s13  \\\n",
       "0   0   1  0.726248  0.242424  0.109755    0  0.369048  0.633262  0.205882   \n",
       "1   0   1  0.628019  0.212121  0.100242    0  0.380952  0.765458  0.279412   \n",
       "2   0   1  0.710145  0.272727  0.140043    0  0.250000  0.795309  0.220588   \n",
       "3   0   1  0.740741  0.318182  0.124518    0  0.166667  0.889126  0.294118   \n",
       "4   0   1  0.668277  0.242424  0.149960    0  0.255952  0.746269  0.235294   \n",
       "\n",
       "        s14       s15  s16       s17  s18  s19       s20       s21  \\\n",
       "0  0.199608  0.363986    0  0.333333    0    0  0.713178  0.724662   \n",
       "1  0.162813  0.411312    0  0.333333    0    0  0.666667  0.731014   \n",
       "2  0.171793  0.357445    0  0.166667    0    0  0.627907  0.621375   \n",
       "3  0.174889  0.166603    0  0.333333    0    0  0.573643  0.662386   \n",
       "4  0.174734  0.402078    0  0.416667    0    0  0.589147  0.704502   \n",
       "\n",
       "   cycle_norm  RUL  label1  label2  \n",
       "0     0.00000  191       0       0  \n",
       "1     0.00277  190       0       0  \n",
       "2     0.00554  189       0       0  \n",
       "3     0.00831  188       0       0  \n",
       "4     0.01108  187       0       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important note is that the target variable needs to have balanced distribution for us to decide which metrics that is suitable to be used for model evaluation. So, we will check for distribution of target variable first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes in train dataset: Counter({0: 17531, 1: 3100})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "cycle         0\n",
       "setting1      0\n",
       "setting2      0\n",
       "setting3      0\n",
       "s1            0\n",
       "s2            0\n",
       "s3            0\n",
       "s4            0\n",
       "s5            0\n",
       "s6            0\n",
       "s7            0\n",
       "s8            0\n",
       "s9            0\n",
       "s10           0\n",
       "s11           0\n",
       "s12           0\n",
       "s13           0\n",
       "s14           0\n",
       "s15           0\n",
       "s16           0\n",
       "s17           0\n",
       "s18           0\n",
       "s19           0\n",
       "s20           0\n",
       "s21           0\n",
       "cycle_norm    0\n",
       "RUL           0\n",
       "label1        0\n",
       "label2        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Classes in train dataset:', Counter(df_train[\"label1\"])) # show the class distribution, and here we observe\n",
    "                                                                # high imbalance with ratio of around 3.5 : 1\n",
    "df_train.isna().sum() # shows that there are no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all features are useful for model building. We will first remove some unnecessary features before we proceed with model building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>s11</th>\n",
       "      <th>s12</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s17</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>cycle_norm</th>\n",
       "      <th>label1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>1</td>\n",
       "      <td>0.726248</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.109755</td>\n",
       "      <td>0.369048</td>\n",
       "      <td>0.633262</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.199608</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.724662</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>1</td>\n",
       "      <td>0.628019</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.100242</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.765458</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.162813</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731014</td>\n",
       "      <td>0.00277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>1</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.140043</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.795309</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.171793</td>\n",
       "      <td>0.357445</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.621375</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>1</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.124518</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.889126</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.174889</td>\n",
       "      <td>0.166603</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>0.00831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>1</td>\n",
       "      <td>0.668277</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.149960</td>\n",
       "      <td>0.255952</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.174734</td>\n",
       "      <td>0.402078</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.704502</td>\n",
       "      <td>0.01108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2        s2        s3        s4  s6        s7  \\\n",
       "0   1      1  0.459770  0.166667  0.183735  0.406802  0.309757   1  0.726248   \n",
       "1   1      2  0.609195  0.250000  0.283133  0.453019  0.352633   1  0.628019   \n",
       "2   1      3  0.252874  0.750000  0.343373  0.369523  0.370527   1  0.710145   \n",
       "3   1      4  0.540230  0.500000  0.343373  0.256159  0.331195   1  0.740741   \n",
       "4   1      5  0.390805  0.333333  0.349398  0.257467  0.404625   1  0.668277   \n",
       "\n",
       "         s8        s9       s11       s12       s13       s14       s15  \\\n",
       "0  0.242424  0.109755  0.369048  0.633262  0.205882  0.199608  0.363986   \n",
       "1  0.212121  0.100242  0.380952  0.765458  0.279412  0.162813  0.411312   \n",
       "2  0.272727  0.140043  0.250000  0.795309  0.220588  0.171793  0.357445   \n",
       "3  0.318182  0.124518  0.166667  0.889126  0.294118  0.174889  0.166603   \n",
       "4  0.242424  0.149960  0.255952  0.746269  0.235294  0.174734  0.402078   \n",
       "\n",
       "        s17       s20       s21  cycle_norm  label1  \n",
       "0  0.333333  0.713178  0.724662     0.00000       0  \n",
       "1  0.333333  0.666667  0.731014     0.00277       0  \n",
       "2  0.166667  0.627907  0.621375     0.00554       0  \n",
       "3  0.333333  0.573643  0.662386     0.00831       0  \n",
       "4  0.416667  0.589147  0.704502     0.01108       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's first remove the unnecessary columns\n",
    "drop_columns_list = [\"setting3\", \"s1\", \"s5\", \"s10\", \"s16\", \"s18\", \"s19\", \"RUL\", \"label2\"]\n",
    "df_train = df_train.drop(drop_columns_list, axis=1)\n",
    "df_test = df_test.drop(drop_columns_list, axis=1)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take note of a few things here. First, the 'ID' column should be indicative of which machine that the data is collected, while the 'Cycle' column indicates the time step that the measurement is taken from. The rest all of the variables have values of more or less the same scale, that is within 0 and 1. This could indicate that someone has already performed Min-Max Normalization for us. Nonetheless, we will also perform it later just to be on the safe side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              int64\n",
       "cycle           int64\n",
       "setting1      float64\n",
       "setting2      float64\n",
       "s2            float64\n",
       "s3            float64\n",
       "s4            float64\n",
       "s6              int64\n",
       "s7            float64\n",
       "s8            float64\n",
       "s9            float64\n",
       "s11           float64\n",
       "s12           float64\n",
       "s13           float64\n",
       "s14           float64\n",
       "s15           float64\n",
       "s17           float64\n",
       "s20           float64\n",
       "s21           float64\n",
       "cycle_norm    float64\n",
       "label1          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's also check for the data types\n",
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we need to perform a train-test split so that we can use training dataset to build our model and have some data to evaluate it on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape for y of train dataset:  (20631,)\n",
      "Shape for x of train dataset:  (20631, 20)\n",
      "Shape for y of test dataset:  (13096,)\n",
      "Shape for x of test dataset:  (13096, 20)\n"
     ]
    }
   ],
   "source": [
    "# separate out features and target variable\n",
    "y_train = df_train['label1'].to_numpy() # convert dtype to numpy so that can be easily converted to torch tensor, originally in Pandas\n",
    "x_train = df_train.drop('label1', axis=1).to_numpy()\n",
    "y_test = df_test['label1'].to_numpy()\n",
    "x_test = df_test.drop('label1', axis=1).to_numpy()\n",
    "\n",
    "print('Shape for y of train dataset: ', y_train.shape)\n",
    "print('Shape for x of train dataset: ', x_train.shape)\n",
    "print('Shape for y of test dataset: ', y_test.shape)\n",
    "print('Shape for x of test dataset: ', x_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "# # data pre-processing : min-max normalization\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20631])\n",
      "torch.Size([13096])\n"
     ]
    }
   ],
   "source": [
    "# convert our target variable to Torch Tensor\n",
    "y_train = torch.Tensor(y_train).to(torch.int64)\n",
    "y_test = torch.Tensor(y_test).to(torch.int64)\n",
    "\n",
    "\n",
    "# So by right, the dtype now should be Torch tensor and has 2 columns (since 2 classes)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we need to split and prepare our dataset into format that is suitable for LSTM to be trained on. We will write a helper function to perform this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processor(x_data, y_data, sequence_length):\n",
    "    \"\"\"\n",
    "    Helper function to sample sub-sequence of training data.\n",
    "    Input data must be numpy.\n",
    "    \"\"\"\n",
    "    x, y = [], []\n",
    "\n",
    "    # Fill the batch with random sequences of data\n",
    "    for i in range(x_data.shape[0] - sequence_length):\n",
    "\n",
    "        # copy the sequences of data starting at this index\n",
    "        x.append(x_data[i:i + sequence_length])\n",
    "        y.append(y_data[i + sequence_length])\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples for X train: 20601\n",
      "Total samples for y train: 20601\n",
      "Total samples for X test: 13066\n",
      "Total samples for y test: 13066\n"
     ]
    }
   ],
   "source": [
    "# let's change the data to a suitable format for model to train on\n",
    "x_sequence_train, y_sequence_train = data_processor(x_train, y_train, 30)\n",
    "x_sequence_test, y_sequence_test = data_processor(x_test, y_test, 30)\n",
    "\n",
    "# let's do a sanity check too\n",
    "print(\"Total samples for X train: \" + str(len(x_sequence_train)))\n",
    "print(\"Total samples for y train: \" + str(len(y_sequence_train)))\n",
    "print(\"Total samples for X test: \" + str(len(x_sequence_test)))\n",
    "print(\"Total samples for y test: \" + str(len(y_sequence_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us use the Dataset object to instantiate our dataset, this way it enables the use of len and indexing\n",
    "# This is the preferred way of preparing data in Pytorch\n",
    "class MaintenanceDataset(torch.utils.data.dataset.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.Tensor(x)\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also do a sanity check after using Dataset class of PyTorch to ensure that we have prepared our data into the right format before we feed them into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.0000, 0.0000, 0.4598,  ..., 0.7132, 0.7247, 0.0000],\n",
      "         [0.0000, 0.0028, 0.6092,  ..., 0.6667, 0.7310, 0.0028],\n",
      "         [0.0000, 0.0055, 0.2529,  ..., 0.6279, 0.6214, 0.0055],\n",
      "         ...,\n",
      "         [0.0000, 0.0748, 0.3621,  ..., 0.6744, 0.5384, 0.0748],\n",
      "         [0.0000, 0.0776, 0.5690,  ..., 0.6124, 0.6428, 0.0776],\n",
      "         [0.0000, 0.0803, 0.3736,  ..., 0.7054, 0.7136, 0.0803]],\n",
      "\n",
      "        [[0.0000, 0.0028, 0.6092,  ..., 0.6667, 0.7310, 0.0028],\n",
      "         [0.0000, 0.0055, 0.2529,  ..., 0.6279, 0.6214, 0.0055],\n",
      "         [0.0000, 0.0083, 0.5402,  ..., 0.5736, 0.6624, 0.0083],\n",
      "         ...,\n",
      "         [0.0000, 0.0776, 0.5690,  ..., 0.6124, 0.6428, 0.0776],\n",
      "         [0.0000, 0.0803, 0.3736,  ..., 0.7054, 0.7136, 0.0803],\n",
      "         [0.0000, 0.0831, 0.5805,  ..., 0.6202, 0.6091, 0.0831]]]), [tensor(0), tensor(0)])\n",
      "20601\n",
      "2\n",
      "30\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# creating train and test datasets\n",
    "train_ds = MaintenanceDataset(x_sequence_train, y_sequence_train)\n",
    "test_ds = MaintenanceDataset(x_sequence_test, y_sequence_test)\n",
    "\n",
    "# let us print out the first two rows of train dataset and check the shape of dataset too\n",
    "print(train_ds[:2])\n",
    "print(len(train_ds))          # print out number of samples\n",
    "print(len(train_ds[0]))       # print out ?\n",
    "print(len(train_ds[0][0]))    # print out number of sequences / sequence length\n",
    "print(len(train_ds[0][0][0])) # print out number of features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13066\n",
      "2\n",
      "30\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# let us print out the shape of the dataset\n",
    "print(len(test_ds))          # print out number of samples\n",
    "print(len(test_ds[0]))       # print out ?\n",
    "print(len(test_ds[0][0]))    # print out number of sequences / sequence length\n",
    "print(len(test_ds[0][0][0])) # print out number of label columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, after preparing it into the right format, we will use DataLoader to transform our data into iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we are ready to create iterator using DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_ds,\n",
    "                                          batch_size=200,\n",
    "                                          shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_ds,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[0.0000, 0.0000, 0.6322, 0.7500, 0.5452, 0.3107, 0.2694, 1.0000,\n",
       "           0.6522, 0.2121, 0.1276, 0.2083, 0.6461, 0.2206, 0.1322, 0.3090,\n",
       "           0.3333, 0.5581, 0.6618, 0.0000],\n",
       "          [0.0000, 0.0028, 0.3448, 0.2500, 0.1506, 0.3796, 0.2223, 1.0000,\n",
       "           0.8052, 0.1667, 0.1467, 0.3869, 0.7399, 0.2647, 0.2048, 0.2132,\n",
       "           0.4167, 0.6822, 0.6868, 0.0028],\n",
       "          [0.0000, 0.0055, 0.5172, 0.5833, 0.3765, 0.3466, 0.3222, 1.0000,\n",
       "           0.6860, 0.2273, 0.1581, 0.3869, 0.6994, 0.2206, 0.1556, 0.4586,\n",
       "           0.4167, 0.7287, 0.7213, 0.0055],\n",
       "          [0.0000, 0.0083, 0.7414, 0.5000, 0.3705, 0.2852, 0.4080, 1.0000,\n",
       "           0.6795, 0.1970, 0.1057, 0.2560, 0.5736, 0.2500, 0.1701, 0.2570,\n",
       "           0.2500, 0.6667, 0.6621, 0.0083],\n",
       "          [0.0000, 0.0111, 0.5805, 0.5000, 0.3916, 0.3521, 0.3320, 1.0000,\n",
       "           0.6940, 0.1667, 0.1024, 0.2738, 0.7377, 0.2206, 0.1528, 0.3009,\n",
       "           0.1667, 0.6589, 0.7164, 0.0111],\n",
       "          [0.0000, 0.0139, 0.5690, 0.7500, 0.2711, 0.1761, 0.2174, 1.0000,\n",
       "           0.7037, 0.1515, 0.1312, 0.2440, 0.6887, 0.2941, 0.1420, 0.3805,\n",
       "           0.3333, 0.5969, 0.6248, 0.0139],\n",
       "          [0.0000, 0.0166, 0.5000, 0.6667, 0.2711, 0.2681, 0.3813, 1.0000,\n",
       "           0.6506, 0.2273, 0.1331, 0.2738, 0.7079, 0.2647, 0.1808, 0.2559,\n",
       "           0.2500, 0.5504, 0.6918, 0.0166],\n",
       "          [0.0000, 0.0194, 0.5345, 0.5000, 0.4006, 0.2147, 0.3147, 1.0000,\n",
       "           0.6023, 0.2273, 0.1397, 0.2143, 0.7249, 0.2647, 0.1341, 0.3709,\n",
       "           0.4167, 0.7054, 0.5913, 0.0194],\n",
       "          [0.0000, 0.0222, 0.2931, 0.5000, 0.2018, 0.4851, 0.5069, 1.0000,\n",
       "           0.7472, 0.2424, 0.1203, 0.3095, 0.7122, 0.2500, 0.1765, 0.4248,\n",
       "           0.2500, 0.7442, 0.7704, 0.0222],\n",
       "          [0.0000, 0.0249, 0.3563, 0.4167, 0.2590, 0.3098, 0.2767, 1.0000,\n",
       "           0.7134, 0.2121, 0.1356, 0.1726, 0.7058, 0.2647, 0.1762, 0.3247,\n",
       "           0.2500, 0.5659, 0.6736, 0.0249],\n",
       "          [0.0000, 0.0277, 0.5402, 0.1667, 0.2500, 0.2178, 0.3643, 1.0000,\n",
       "           0.7794, 0.2121, 0.1343, 0.2262, 0.6951, 0.2647, 0.1674, 0.2578,\n",
       "           0.2500, 0.7132, 0.6444, 0.0277],\n",
       "          [0.0000, 0.0305, 0.6494, 0.7500, 0.4006, 0.3573, 0.2628, 1.0000,\n",
       "           0.7246, 0.1818, 0.1269, 0.2500, 0.7079, 0.2647, 0.1671, 0.2828,\n",
       "           0.2500, 0.7519, 0.6770, 0.0305],\n",
       "          [0.0000, 0.0332, 0.1782, 0.7500, 0.2199, 0.3935, 0.3661, 1.0000,\n",
       "           0.6747, 0.1818, 0.1074, 0.2976, 0.7846, 0.2206, 0.1609, 0.3528,\n",
       "           0.3333, 0.7287, 0.6538, 0.0332],\n",
       "          [0.0000, 0.0360, 0.5977, 0.1667, 0.3072, 0.2642, 0.3482, 1.0000,\n",
       "           0.7746, 0.1970, 0.1058, 0.2321, 0.6951, 0.2647, 0.1567, 0.4017,\n",
       "           0.3333, 0.6899, 0.7774, 0.0360],\n",
       "          [0.0000, 0.0388, 0.4828, 0.2500, 0.3886, 0.3002, 0.2792, 1.0000,\n",
       "           0.6924, 0.1515, 0.1385, 0.2976, 0.5736, 0.1765, 0.1738, 0.3517,\n",
       "           0.3333, 0.6977, 0.6531, 0.0388],\n",
       "          [0.0000, 0.0416, 0.3966, 0.7500, 0.3343, 0.2937, 0.4306, 1.0000,\n",
       "           0.6393, 0.3030, 0.0907, 0.3214, 0.7399, 0.3235, 0.1749, 0.4044,\n",
       "           0.1667, 0.5659, 0.6272, 0.0416],\n",
       "          [0.0000, 0.0443, 0.5805, 0.6667, 0.2952, 0.2542, 0.3692, 1.0000,\n",
       "           0.7359, 0.2424, 0.1082, 0.2500, 0.7249, 0.2059, 0.1385, 0.5110,\n",
       "           0.2500, 0.7364, 0.6168, 0.0443],\n",
       "          [0.0000, 0.0471, 0.7011, 0.5833, 0.4157, 0.3377, 0.3619, 1.0000,\n",
       "           0.5878, 0.2121, 0.1184, 0.3512, 0.7356, 0.2647, 0.1717, 0.4132,\n",
       "           0.2500, 0.6357, 0.7648, 0.0471],\n",
       "          [0.0000, 0.0499, 0.6667, 0.5833, 0.3675, 0.3170, 0.3385, 1.0000,\n",
       "           0.6473, 0.1667, 0.1129, 0.2381, 0.7186, 0.1912, 0.1516, 0.2474,\n",
       "           0.2500, 0.7132, 0.6721, 0.0499],\n",
       "          [0.0000, 0.0526, 0.5632, 0.4167, 0.4217, 0.3649, 0.3114, 1.0000,\n",
       "           0.7182, 0.2273, 0.0870, 0.3631, 0.7655, 0.2500, 0.1478, 0.3270,\n",
       "           0.3333, 0.6667, 0.6052, 0.0526],\n",
       "          [0.0000, 0.0554, 0.7184, 0.3333, 0.4488, 0.2673, 0.2861, 1.0000,\n",
       "           0.7359, 0.2273, 0.1436, 0.3036, 0.7164, 0.3382, 0.1389, 0.3559,\n",
       "           0.3333, 0.6357, 0.7019, 0.0554],\n",
       "          [0.0000, 0.0582, 0.5690, 0.5833, 0.3735, 0.2559, 0.3682, 1.0000,\n",
       "           0.5765, 0.1515, 0.1109, 0.2440, 0.5800, 0.2353, 0.1494, 0.5033,\n",
       "           0.3333, 0.6202, 0.6667, 0.0582],\n",
       "          [0.0000, 0.0609, 0.5517, 0.5000, 0.2741, 0.3591, 0.2167, 1.0000,\n",
       "           0.8406, 0.2121, 0.1361, 0.2024, 0.7058, 0.2647, 0.1601, 0.3336,\n",
       "           0.4167, 0.7442, 0.5860, 0.0609],\n",
       "          [0.0000, 0.0637, 0.4655, 0.4167, 0.3343, 0.5069, 0.3022, 1.0000,\n",
       "           0.5507, 0.2576, 0.0969, 0.2619, 0.7186, 0.3529, 0.1587, 0.3174,\n",
       "           0.4167, 0.6202, 0.6944, 0.0637],\n",
       "          [0.0000, 0.0665, 0.6609, 0.2500, 0.3133, 0.2483, 0.3035, 1.0000,\n",
       "           0.6296, 0.3182, 0.0990, 0.3095, 0.7612, 0.2941, 0.1482, 0.2917,\n",
       "           0.4167, 0.6357, 0.6687, 0.0665],\n",
       "          [0.0000, 0.0693, 0.7701, 0.0833, 0.3825, 0.2668, 0.4359, 1.0000,\n",
       "           0.7633, 0.2727, 0.1422, 0.2857, 0.6951, 0.2794, 0.1506, 0.2693,\n",
       "           0.2500, 0.4884, 0.6373, 0.0693],\n",
       "          [0.0000, 0.0720, 0.4598, 0.5833, 0.2620, 0.3403, 0.3049, 1.0000,\n",
       "           0.7246, 0.2879, 0.1094, 0.2917, 0.6674, 0.2059, 0.1409, 0.4790,\n",
       "           0.3333, 0.5659, 0.6889, 0.0720],\n",
       "          [0.0000, 0.0748, 0.6264, 0.9167, 0.2169, 0.5060, 0.3214, 1.0000,\n",
       "           0.5974, 0.2576, 0.1518, 0.1190, 0.6716, 0.2794, 0.1804, 0.4698,\n",
       "           0.3333, 0.5349, 0.6297, 0.0748],\n",
       "          [0.0000, 0.0776, 0.5805, 0.5833, 0.2229, 0.3512, 0.2677, 1.0000,\n",
       "           0.6924, 0.2727, 0.1094, 0.3393, 0.7889, 0.2794, 0.1713, 0.3705,\n",
       "           0.3333, 0.6822, 0.6461, 0.0776],\n",
       "          [0.0000, 0.0803, 0.3563, 0.8333, 0.4759, 0.3200, 0.3160, 1.0000,\n",
       "           0.6844, 0.2879, 0.1154, 0.3274, 0.6588, 0.3235, 0.1798, 0.3313,\n",
       "           0.2500, 0.7364, 0.7080, 0.0803]]]),\n",
       " tensor([0])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or we can also just load one batch of the iterator as checking\n",
    "next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform some needed configuration for the model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x20ac7e0c510>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is just to configure model hyperparameters\n",
    "# Input configurations\n",
    "input_size = 20      # since one row has 20 features, we are reading one row at a time\n",
    "sequence_length = 30 # since there are 30 rows \n",
    "num_layers = 2       # stack 2 RNN together\n",
    "\n",
    "# Hyperparameter\n",
    "hidden_size = 128 # i think this is the number of hidden nodes\n",
    "num_classes = 2\n",
    "epochs = 5\n",
    "# batch_size = 200\n",
    "learning_rate = 0.001\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed) # to ensure reproducivility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(20, 128, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "104\n",
      "Epoch [1/5], Step [100/104], Loss:     0.1841\n",
      "Epoch [2/5], Step [100/104], Loss:     0.1500\n",
      "Epoch [3/5], Step [100/104], Loss:     0.1377\n",
      "Epoch [4/5], Step [100/104], Loss:     0.1326\n",
      "Epoch [5/5], Step [100/104], Loss:     0.1304\n"
     ]
    }
   ],
   "source": [
    "# Let's instantiate a model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__() # this is for backward compatibility of Python 2, same as super().__init()\n",
    "        self.hidden_size = hidden_size # this is to set attribute of the instance\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True) # in this order, so (28, 128, 2)\n",
    "                                                                                 # batch_first set number of batch as 1st dimension\n",
    "        # x -> (batch_size, seq, input_size) [the shape needed for the tensor]\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size) # initiate zeros tensor with (num_layers, batch_size, hidden_size)\n",
    "        \n",
    "        out, _ = self.rnn(x, h0)\n",
    "        # output shape: batch_size, seq_length, hidden_size\n",
    "        # out (N, 28, 128)\n",
    "        out = out[:, -1, :]\n",
    "        # out (N, 128)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes)\n",
    "print(model)\n",
    "\n",
    "# let's set loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss() # since this is a binary class problem\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# finally we can start to train\n",
    "n_total_steps = len(train_loader)\n",
    "print(n_total_steps)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (x, y) in enumerate(train_loader):          \n",
    "        # forward pass\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad() # this is to clear the parameters, done before each backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print out the training performance\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():10.4f}')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images:      98.45 %\n"
     ]
    }
   ],
   "source": [
    "# Let's evaluate our model\n",
    "# Remember, we don't need to compute gradients as it is not required (and save some precious memory too!)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for x, y in test_loader:\n",
    "        outputs = model(x)\n",
    "        # max returns (value, index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += y.size(0)\n",
    "        n_correct += (predicted == y).sum().item()\n",
    "        \n",
    "acc = 100.0 * n_correct / n_samples\n",
    "print(f\"Accuracy of the network on the 10000 test images: {acc:10.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, our model has a great accuracy! But this does not mean that it is a very good model, probably is due to the imbalance class issue and that the model just predicted the major classes. We can check out other classification metrics like precision, recall, and F1-score to evaluate it in further modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please perform binary classification task using the same dataset and features but instead choose the target variable of \"label2\". Feel free to experiment with other features or use feature engineering techniques in case you have an adventurous spirit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# read dataset\n",
    "\n",
    "# initial data exploration\n",
    "\n",
    "# data pre-processing\n",
    "\n",
    "# model configuration\n",
    "\n",
    "# model building\n",
    "\n",
    "# model evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"reference\">Reference</a>:\n",
    "1. [Deep Learning for tabular data using Pytorch](ttps://jovian.ai/aakanksha-ns/shelter-outcome)\n",
    "2. [pytorch custom dataset: DataLoader returns a list of tensors rather than tensor of a list](https://stackoverflow.com/questions/62208904/pytorch-custom-dataset-dataloader-returns-a-list-of-tensors-rather-than-tensor)\n",
    "3. [Predictive maintenance - NASA Turbofan Dataset](https://www.kaggle.com/c/predictive-maintenance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}