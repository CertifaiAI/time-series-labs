{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "![logo](../../picture/license_header_logo.png)\n",
    "> **Copyright &copy; 2020 - 2021 CertifAI Sdn. Bhd.**<br>\n",
    " <br>\n",
    "This program and the accompanying materials are made available under the\n",
    "terms of the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). <br>\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n",
    "WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n",
    "License for the specific language governing permissions and limitations\n",
    "under the License. <br>\n",
    "<br>**SPDX-License-Identifier: Apache-2.0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirement\n",
    "You should complete the LSTM tutorial before starting the CNN tutorial. This is because most of the functions used will be based on `data_module.py` and `deep_learning_module.py`\n",
    "\n",
    "Please proceed to the LSTM notebook if you haven't complete it.<br>\n",
    "\n",
    "1. [04 - LSTM_Univariate_SingleStep](./04%20-%20LSTM_Univariate_SingleStep.ipynb)\n",
    "2. [04 - LSTM_Univariate_MultiStep.ipynb](./04%20-%20LSTM_Univariate_MultiStep.ipynb)\n",
    "3. [04 - LSTM_Multivariate_Univariate_SingleStep](./04%20-%20LSTM_Multivariate_Univariate_SingleStep.ipynb)<br>\n",
    "4. [04 - LSTM_Multivariate_Univariate_MultiStep](./04%20-%20LSTM_Multivariate_Univariate_MultiStep.ipynb)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Input, Univariate Output CNN, Multi-Step\n",
    "This tutorial is to demonstrate the process of building a CNN mdoel for Multivariate Input, Univariate Output for Multi-Step.<br>\n",
    "\n",
    "It consists of 2 major parts which are:<br>\n",
    "\n",
    "Part 1 - The Demonstration of Building CNN using Synthetic data<br>\n",
    "Part 2 - Exercise of building CNN using COVID-19 Data. <br>\n",
    "\n",
    "## What will we accomplish?\n",
    "First, we will show the step in building the CNN :\n",
    "\n",
    "Step 1. Data Preparation (Data Splitting,Data Sequencing,Data Standardization and Batching the Data) <br>\n",
    "Step 2. Model Configuration for CNN<br>\n",
    "Step 3. Train the model<br>\n",
    "Step 4. Validate the model using graph<br>\n",
    "Step 5. Evaluation Metrics such as MSE<br>\n",
    "Step 6. Plot the forecast result<br>\n",
    "\n",
    "Let's import the package needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler , MinMaxScaler\n",
    "import math\n",
    "from torchsummaryX import summary\n",
    "\n",
    "# To auto load the customise module\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import deep_learning_module\n",
    "import data_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter\n",
    "Define the hyperparameter that is needed to tune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.70\n",
    "num_epochs = 200\n",
    "window_size = 5\n",
    "batch_size = 5\n",
    "n_step = 2\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 : Data Preparation\n",
    "We create synthetic data to make sure the model is created correctly and has the ability to perform forecasting. <br>\n",
    "\n",
    "1. First, we will create a sequence of data with `np.array`.\n",
    "2. Then, we will assign a date to the sequence of data with `pd.date_range` and store it in a series format by using `pd.Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Synthetic Data\n",
    "in_seq1 = np.array([x for x in range(0, 300, 10)])\n",
    "in_seq2 = np.array([x for x in range(5, 305, 10)])\n",
    "out_seq = np.array([in_seq1[i] + in_seq2[i] for i in range(len(in_seq1))])\n",
    "\n",
    "\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "\n",
    "# horizontally stack columns\n",
    "dataset = np.hstack((in_seq1, in_seq2, out_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_seq1</th>\n",
       "      <th>in_seq2</th>\n",
       "      <th>out_seq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04</th>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            in_seq1  in_seq2  out_seq\n",
       "Date                                 \n",
       "2020-01-01        0        5        5\n",
       "2020-01-02       10       15       25\n",
       "2020-01-03       20       25       45\n",
       "2020-01-04       30       35       65\n",
       "2020-01-05       40       45       85"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.DataFrame(dataset,columns =[\"in_seq1\",\"in_seq2\",\"out_seq\"],\n",
    "                      index = pd.date_range(\"1/1/2020\",periods=len(dataset),freq='D'))\n",
    "dataset.index.name=\"Date\"\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "Data visualization is important for us to visualize the pattern of data such as trend and seasonality. As seen in the graph below, there is an increasing trend in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Synthetic Data')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.plot()\n",
    "plt.title(\"Synthetic Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting\n",
    "In Deep Learning, we will split the data into training and test dataset. The training data is used to train the model whereas the test data is used to validate the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the split ratio \n",
    "split_data = round(len(dataset)*split_ratio)\n",
    "split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_shape\n",
      "(21, 3)\n",
      "test_data_shape\n",
      "(9, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split data by indexing \n",
    "train_data = dataset[:split_data]\n",
    "test_data = dataset[split_data:]\n",
    "train_time = dataset.index[:split_data]\n",
    "test_time = dataset.index[split_data:]\n",
    "print(\"train_data_shape\")\n",
    "print(train_data.shape)\n",
    "print(\"test_data_shape\")\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Standardization\n",
    "Standardize your numeric attributes to have 0 mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_standardized(21, 3)\n",
      "test_data_standardized(9, 3)\n"
     ]
    }
   ],
   "source": [
    "data_scalers,train_data_standard, test_data_standard = data_module.multi_data_scaler(train_data,test_data)\n",
    "print(\"train_data_standardized\"+str(train_data_standard.shape))\n",
    "print(\"test_data_standardized\"+str(test_data_standard.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sequencing\n",
    "Sequencing the data by taking in the multivariate series into `x-feature` and `y-label`\n",
    "<img src = \"../../picture/multivariate univariate.png\"  width=\"300\" height  =\"300\" align=\"center\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape:(16, 5, 2) trainY shape:(16, 2)\n",
      "\n",
      "testX shape:(4, 5, 2) testY shape:(4, 2)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainY = data_module.multivariate_univariate_multi_step(train_data_standard, window_size,n_step)\n",
    "testX, testY = data_module.multivariate_univariate_multi_step(test_data_standard, window_size,n_step)\n",
    "print(f\"trainX shape:{trainX.shape} trainY shape:{trainY.shape}\\n\")\n",
    "print(f\"testX shape:{testX.shape} testY shape:{testY.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainY shape:(16, 2, 1)\n",
      "testY shape:(4, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "trainY = trainY.reshape(trainY.shape[0],n_step,1)\n",
    "testY = testY.reshape(testY.shape[0],n_step,1)\n",
    "print(f\"trainY shape:{trainY.shape}\")\n",
    "print(f\"testY shape:{testY.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transform\n",
    "Data needs to be transformed from `NumPy` to `PyTorch` tensor before being fed into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dict ,test_data_dict = data_module.key_assign(trainingX = trainX  , \n",
    "                       testingX = testX, \n",
    "                       trainingY = trainY, \n",
    "                       testingY = testY)\n",
    "\n",
    "train_data_dict ,test_data_dict = data_module.transform(train_data_dict ,test_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_x_feature shape : torch.Size([16, 5, 2])\n",
      "train_data_y_label shape : torch.Size([16, 2, 1])\n",
      "test_data_x_feature shape : torch.Size([4, 5, 2])\n",
      "test_data_y_label shape : torch.Size([4, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "data_module.sanity_check(train_data_dict , test_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transpose \n",
    "You are required to transpose the x-feature data in such a way that : <br>\n",
    ">`(batch_size, number_of_features, sequence_length)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transpose to suit for CNN \n",
    "train_data_dict , test_data_dict= data_module.transpose(train_data_dict,test_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_x_feature shape : torch.Size([16, 2, 5])\n",
      "train_data_y_label shape : torch.Size([16, 2, 1])\n",
      "test_data_x_feature shape : torch.Size([4, 2, 5])\n",
      "test_data_y_label shape : torch.Size([4, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "data_module.sanity_check(train_data_dict , test_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Iterator\n",
    "Iterator is created to separate the data into several batches to fasten the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter , test_iter = data_module.iterator(train_data_dict ,test_data_dict,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 :  CNN Model Configuration\n",
    "You may choose to use the CNN configuration that have been saved in the `deep_learning_module.py` or code it by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self,n_feature,n_step):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.n_feature = n_feature\n",
    "        self.n_step = n_step\n",
    "\n",
    "        # Conv1d in_channels is base on num time series\n",
    "        # Input:(N,C,Lin) Output : (N,C,Lout)\n",
    "        self.conv1 = nn.Conv1d(in_channels = n_feature, out_channels = 30, kernel_size = 2)\n",
    "        \n",
    "        # For example Input:(N,C,Lin) Output : (N,C,Lout)\n",
    "        self.poo1 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(in_channels = 30, out_channels = 20, kernel_size = 2)\n",
    "        \n",
    "        # AdaptiveMaxPool1d use to make sure it always will output  = 1 ,to make sure return the correct batch size \n",
    "        self.pool2 = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc1 = nn.Linear(20, 10)\n",
    "        self.fc2 = nn.Linear(10,n_step)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.poo1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1,20)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Model\n",
    "The number of features and number of steps are fed as attributes into the model. The other attributes such as `kernel_size` , `in_channels` and `out_channels` for each convolution layer need to configured in the network configuration by the practitioner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed\n",
    "torch.manual_seed(123)\n",
    "### BEGIN SOLUTION\n",
    "n_feature = train_data_dict['train_data_x_feature'].shape[1]\n",
    "\n",
    "# Input the attribute need by the model \n",
    "model = CNN(n_feature = n_feature,n_step = n_step )\n",
    "\n",
    "# Define the optimizer (Here we use SGD as our optimizer)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the loss function (Here we use MSE as the loss function)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================\n",
      "        Kernel Shape Output Shape Params Mult-Adds\n",
      "Layer                                             \n",
      "0_conv1   [2, 30, 2]   [5, 30, 4]  150.0     480.0\n",
      "1_poo1             -   [5, 30, 2]      -         -\n",
      "2_conv2  [30, 20, 2]   [5, 20, 1]  1.22k      1.2k\n",
      "3_pool2            -   [5, 20, 1]      -         -\n",
      "4_fc1       [20, 10]      [5, 10]  210.0     200.0\n",
      "5_fc2        [10, 2]       [5, 2]   22.0      20.0\n",
      "----------------------------------------------------\n",
      "                      Totals\n",
      "Total params          1.602k\n",
      "Trainable params      1.602k\n",
      "Non-trainable params     0.0\n",
      "Mult-Adds               1.9k\n",
      "====================================================\n",
      "        Kernel Shape Output Shape  Params  Mult-Adds\n",
      "Layer                                               \n",
      "0_conv1   [2, 30, 2]   [5, 30, 4]   150.0      480.0\n",
      "1_poo1             -   [5, 30, 2]     NaN        NaN\n",
      "2_conv2  [30, 20, 2]   [5, 20, 1]  1220.0     1200.0\n",
      "3_pool2            -   [5, 20, 1]     NaN        NaN\n",
      "4_fc1       [20, 10]      [5, 10]   210.0      200.0\n",
      "5_fc2        [10, 2]       [5, 2]    22.0       20.0\n"
     ]
    }
   ],
   "source": [
    "seq_length = train_data_dict['train_data_x_feature'].shape[2]\n",
    "inputs = torch.zeros((batch_size,n_feature ,seq_length),dtype=torch.float) # batch size ,input_dim ,seq_length\n",
    "print(summary(model,inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv1d(2, 30, kernel_size=(2,), stride=(1,))\n",
       "  (poo1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(30, 20, kernel_size=(2,), stride=(1,))\n",
       "  (pool2): AdaptiveMaxPool1d(output_size=1)\n",
       "  (fc1): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (fc2): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seed\n",
    "torch.manual_seed(123)\n",
    "\n",
    "#  Xavier Weight Initialize \n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        \n",
    "model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 : Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Training\n",
    "# seed\n",
    "torch.manual_seed(123)\n",
    "# Start Training\n",
    "train_loss, val_loss = deep_learning_module.training(num_epochs, train_iter, test_iter, optimizer, loss_fn, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 : Validation \n",
    "A learning curve is plotted to define how well the data fits in the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.learning_curve(num_epochs = num_epochs , train_loss = train_loss , val_loss = val_loss )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 : Evaluation\n",
    "This section is to inference the model by feeding in testing data, determining the output forecast value and calculating the RMSE.\n",
    "\n",
    "It consists of 4 sections :\n",
    "\n",
    "Section 1 : Feed in the train and test data to the model <br>\n",
    "Section 2 : Reshape both to the original data dimension <br> \n",
    "Section 3 : Invert the scaling back to the original data value <br>\n",
    "Section 4 : Calculate the RMSE of train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1 : make predictions\n",
    "with torch.no_grad():\n",
    "    y_train_prediction = model(train_data_dict['train_data_x_feature'])\n",
    "    y_test_prediction = model(test_data_dict['test_data_x_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign evaluation key\n",
    "\n",
    "prediction , output = data_module.key_assign_evaluation(y_train_prediction,\n",
    "                                                        y_test_prediction,\n",
    "                                                        train_data_dict,\n",
    "                                                        test_data_dict)\n",
    "# Section 2 : Reshape to original data\n",
    "# Squeeze the output dimension\n",
    "output_data = data_module.squeeze_dimension(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.sanity_check(data_1 = output_data,data_2 = {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3 : Invert the scaling back to the original data value\n",
    "output_data_scaler = data_scalers[list(data_scalers)[-1]]\n",
    "prediction = data_module.inverse_scaler(prediction,output_data_scaler)\n",
    "output_data  = data_module.inverse_scaler(output_data ,output_data_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the forecast value\n",
    "data_module.list_forecast_value(output_data,prediction) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 4 : Calculate the RMSE of train and test data\n",
    "### BEGIN SOLUTION\n",
    "trainScore,testScore = data_module.rmse(prediction,output_data)\n",
    "### END SOLUTION\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 : Forecast Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.multi_step_plot(original_test_data = test_data[\"out_seq\"],\n",
    "                            after_sequence_test_data = output_data,\n",
    "                            forecast_data = prediction,\n",
    "                            test_time = test_time,\n",
    "                            window_size = window_size,\n",
    "                            n_step = n_step,\n",
    "                            details={},\n",
    "                            original_plot=True,\n",
    "                            multivariate = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 : Exercise for Multivariate Multi-step\n",
    "## Task : Predicting the total number of death cases in COVID-19 Malaysia 3 days into the future\n",
    "\n",
    "### Introduction \n",
    "You are given a set of data that contains information about COVID-19 cases worldwide. You are required to perform some data analysis on it and predict the death cases.<br>\n",
    "\n",
    "Please follow the instruction and try to code the exercise. Please feel free to use online resources to find out how to use a particular function in the data exploration part<br>\n",
    "\n",
    "\n",
    "\n",
    "Data Source : \n",
    "https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter\n",
    ">**Instruction** : <br>\n",
    "You are required to fill `None` with a suitable value to make the model converge\n",
    "\n",
    ">**Expected Result** : <br>\n",
    "Train Score <= 10 RMSE<br>\n",
    "Test Score <= 10 RMSE<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperameter\n",
    "split_ratio_covid = 0.70\n",
    "num_epochs_covid = 100\n",
    "window_size_covid = 10\n",
    "n_step_covid = 3\n",
    "learning_rate_covid = 0.001\n",
    "batch_size_covid = 5\n",
    "#seed\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 : Data Preparation\n",
    "In this tutorial, you will face a complex real-world dataset. You are required to use some of the data exploration technique to help you prepare the data.\n",
    "\n",
    ">**Instruction** : <br>\n",
    "Read the file using `pd.read_csv`<br>\n",
    "Save your data as `cases`<br>\n",
    "Your file path `../../datasets/others/covid_19_data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "cases = pd.read_csv(\"../../datasets/others/covid_19_data.csv\")\n",
    "### END SOLUTION\n",
    "cases.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data contain info on COVID-19 cases from other countries as well. Hence, you need to slice the COVID-19 info only for Malaysia.\n",
    "\n",
    ">**Instruction** : <br>\n",
    "Slice the COVID-19 info only for Malaysia. You might need to use `df.loc[]` to help you slice the data.\n",
    "\n",
    ">**Expected Result** :<br>\n",
    "Example of first 5 row data :\n",
    "\n",
    "---\t|SNo\t|ObservationDate\t|Province/State\t|Country/Region\t|Last Update\t|Confirmed\t|Deaths\t|Recovered\n",
    " ---|---\t|---\t            |---\t        |---\t        |---\t        |---\t    |---\t|---\n",
    "78\t|79\t    |01/23/2020\t|NaN\t|Malaysia\t|1/23/20 |17:00\t|0.0\t|0.0\t|0.0\n",
    "168\t|169\t|01/25/2020\t|NaN\t|Malaysia\t|1/25/20 |17:00\t|3.0\t|0.0\t|0.0\n",
    "214\t|215\t|01/26/2020\t|NaN\t|Malaysia\t|1/26/20 |16:00\t|4.0\t|0.0\t|0.0\n",
    "260\t|261\t|01/27/2020\t|NaN\t|Malaysia\t|1/27/20 |23:59\t|4.0\t|0.0\t|0.0\n",
    "311\t|312\t|01/28/2020\t|NaN\t|Malaysia\t|1/28/20 |23:00\t|4.0\t|0.0\t|0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cases[\"Country/Region\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "new_covid_data = cases.loc[cases[\"Country/Region\"] == 'Malaysia']\n",
    "new_covid_data.head()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make sure there is no missing value in our data\n",
    ">**Instruction** : <br>\n",
    "Use `df.isnull().values.any()` to check any missing data in our dataset. `True` would mean that there is `NaN` in our dataset<br>\n",
    "Most of the column does not contain `NaN` values except for `Province/State `. This is acceptable since this data is not particularly useful to our use case which will be dropped later.\n",
    "\n",
    ">**Expected Result** :<br>\n",
    "\n",
    "Columns|Status\n",
    "---|---\n",
    "SNo                |False\n",
    "ObservationDate    |False\n",
    "Province/State      |True\n",
    "Country/Region     |False\n",
    "Last Update        |False\n",
    "Confirmed          |False\n",
    "Deaths             |False\n",
    "Recovered          |False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "new_covid_data.isnull().any()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Instruction** : <br>\n",
    "Set the `ObservationDate` as the index for the dataset. You are required to convert `ObservationDate` to datetime using `pd.to_datetime()` <br>\n",
    "\n",
    ">**Expected Result** :<br>\n",
    "Example of first 5 row data :\n",
    "\n",
    "ObservationDate\t|SNo\t|ObservationDate\t|Province/State\t|Country/Region\t|Last Update\t|Confirmed\t|Deaths\t|Recovered\n",
    " ---|---\t|---\t            |---\t        |---\t        |---\t        |---\t    |---\t|---\n",
    "01/23/2020\t|79\t    |01/23/2020\t|NaN\t|Malaysia\t|1/23/20 |17:00\t|0.0\t|0.0\t|0.0\n",
    "01/25/2020\t|169\t|01/25/2020\t|NaN\t|Malaysia\t|1/25/20 |17:00\t|3.0\t|0.0\t|0.0\n",
    "01/26/2020\t|215\t|01/26/2020\t|NaN\t|Malaysia\t|1/26/20 |16:00\t|4.0\t|0.0\t|0.0\n",
    "01/27/2020\t|261\t|01/27/2020\t|NaN\t|Malaysia\t|1/27/20 |23:59\t|4.0\t|0.0\t|0.0\n",
    "01/28/2020\t|312\t|01/28/2020\t|NaN\t|Malaysia\t|1/28/20 |23:00\t|4.0\t|0.0\t|0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "new_covid_data = new_covid_data.set_index(pd.to_datetime(new_covid_data[\"ObservationDate\"]))\n",
    "### END SOLUTION\n",
    "\n",
    "new_covid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns such as `SNo`,`ObservationDate`,`Province/State`,`Country/Region`,`Last Update` do not provide any useful information to us. Hence, we need to drop it to make the data look cleaner. \n",
    "\n",
    ">**Instruction** : <br>\n",
    "Use `df.drop` to drop the `columns = ['SNo','ObservationDate','Province/State','Country/Region','Last Update']`<br>\n",
    "\n",
    ">**Expected Result** :<br>\n",
    "\n",
    "ObservationDate\t|Confirmed\t|Deaths\t|Recovered\n",
    "\t---|---|---|---\t\t\n",
    "2020-01-23|\t0.0|\t0.0|\t0.0\n",
    "2020-01-25|\t3.0|\t0.0|\t0.0\n",
    "2020-01-26|\t4.0|\t0.0|\t0.0\n",
    "2020-01-27|\t4.0|\t0.0|\t0.0\n",
    "2020-01-28|\t4.0|    0.0|\t0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "new_covid_data = new_covid_data.drop(columns = ['SNo','ObservationDate','Province/State','Country/Region','Last Update'])\n",
    "### END SOLUTION\n",
    "new_covid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our sliding window function work. You need to rearrange the data columns such that the targeted forecast series will be the last column of the data\n",
    ">**Instruction** : <br>\n",
    "Rearrange the data column using `df[]`<br>\n",
    "For example : <br>\n",
    "columns = [`A`,`B`,`C`]<br>\n",
    "rearrage columns = [`A`,`C`,`B`]<br>\n",
    "`df =  df[rearrage columns]`\n",
    "\n",
    ">**Expected Result** :<br>\n",
    "\n",
    "ObservationDate|\tConfirmed|\tRecovered|\tDeaths\n",
    "\t\t---|---|---|---\t\n",
    "2020-01-23|\t0.0|\t0.0|\t0.0\n",
    "2020-01-25|\t3.0|\t0.0|\t0.0\n",
    "2020-01-26|\t4.0|\t0.0|\t0.0\n",
    "2020-01-27|\t4.0|\t0.0|\t0.0\n",
    "2020-01-28|\t4.0|\t0.0|\t0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "new_covid_data = new_covid_data[[\"Confirmed\",\"Recovered\",\"Deaths\"]]\n",
    "### END SOLUTION\n",
    "new_covid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "Data visualization is important for us to visualize the pattern of data such as trend and seasonality. Seeing the graph below, it is quite clear that there is an increasing trend in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Data \n",
    "axes = new_covid_data[new_covid_data.columns].plot(alpha=1.0, linestyle='-', figsize=(11, 9), subplots=True)\n",
    "for ax in axes:\n",
    "    ax.set_ylabel('COVID-19-Malaysia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the data is in cumulative form. To perform time-series prediction, we need to convert the cumulative cases into daily cases.\n",
    "\n",
    ">**Instruction** : <br>\n",
    "Remove the cumulative counts. You might need to use a `For loop` to loop through the data for each columns .Use `new_covid_data[name] - new_covid_data[name].shift().fillna(0)` as the math operation to remove the cumulative<br>\n",
    "\n",
    ">**Expected Result** :<br>\n",
    "\n",
    "ObservationDate|\tConfirmed|\tRecovered|\tDeaths|\n",
    "\t---|\t---|---|---\t\n",
    "2020-01-23|\t0.0|\t0.0|\t0.0|\n",
    "2020-01-25|\t3.0|\t0.0|\t0.0|\n",
    "2020-01-26|\t1.0|\t0.0|\t0.0|\n",
    "2020-01-27|\t0.0|\t0.0|\t0.0|\n",
    "2020-01-28|\t0.0|\t0.0|\t0.0|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "for name in new_covid_data.columns:\n",
    "        new_covid_data[name] = new_covid_data[name] - new_covid_data[name].shift().fillna(0)\n",
    "### END SOLUTION\n",
    "new_covid_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Data \n",
    "axes = new_covid_data[new_covid_data.columns].plot(alpha=1.0, linestyle='-', figsize=(11, 9), subplots=True)\n",
    "for ax in axes:\n",
    "    ax.set_ylabel('COVID-19-Malaysia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting\n",
    "In Deep Learning, we will split the data into training and test dataset. The training data is used to train the model whereas the test data is used to validate the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data_covid = round(len(dataset)*split_ratio)\n",
    "split_data_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data by indexing \n",
    "train_data_covid = new_covid_data[:-split_data_covid ]\n",
    "test_data_covid = new_covid_data[-split_data_covid :]\n",
    "train_time_covid = new_covid_data.index[:-split_data_covid ]\n",
    "test_time_covid = new_covid_data.index[-split_data_covid :]\n",
    "\n",
    "print(\"train_data_shape\")\n",
    "print(train_data_covid.shape)\n",
    "print(\"test_data_shape\")\n",
    "print(test_data_covid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization \n",
    "Normalize the data into range of 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_covid,train_data_normalized_covid,test_data_normalized_covid = data_module.multi_data_scaler(train_data_covid,\n",
    "                                                                                         test_data_covid,\n",
    "                                                                                         scale_mode = \"Normalize\")\n",
    "print(\"train_data_normalized_demand\"+str(train_data_normalized_covid.shape))\n",
    "print(\"test_data_normalized_demand\"+str(test_data_normalized_covid.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sequencing\n",
    "Sequencing the data by taking in the multivariate series into x-feature and y-label\n",
    "<img src = \"../../picture/multivariate univariate.png\"  width=\"300\" height  =\"300\" align=\"center\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_covid ,trainY_covid=  data_module.multivariate_univariate_multi_step(train_data_normalized_covid,window_size_covid,n_step_covid)\n",
    "testX_covid , testY_covid = data_module.multivariate_univariate_multi_step(test_data_normalized_covid,window_size_covid,n_step_covid)\n",
    "print(f\"trainX_demand shape:{trainX_covid.shape} trainY_demand shape:{trainY_covid.shape}\\n\")\n",
    "print(f\"testX_demand shape:{testX_covid.shape} testY_demand shape:{testY_covid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY_covid = trainY_covid.reshape(trainY_covid.shape[0],n_step_covid,1)\n",
    "testY_covid= testY_covid.reshape(testY_covid.shape[0],n_step_covid,1)\n",
    "print(f\"trainY shape:{trainY_covid.shape}\")\n",
    "print(f\"testY shape:{testY_covid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transform\n",
    "Data needs to be transformed from numpy to pytorch tensor before being fed into the model.\n",
    "\n",
    ">**Instruction** : <br>\n",
    "Use `data_module.key_assign` to assign the key and `data_module.transform` to transform the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "train_data_dict_covid ,test_data_dict_covid = data_module.key_assign(trainingX = trainX_covid  , \n",
    "                       testingX = testX_covid, \n",
    "                       trainingY = trainY_covid, \n",
    "                       testingY = testY_covid)\n",
    "train_data_dict_covid ,test_data_dict_covid = data_module.transform(train_data_dict_covid ,test_data_dict_covid)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.sanity_check(train_data_dict_covid , test_data_dict_covid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transpose \n",
    "You are require to transpose the x-feature data in such a way that : <br>\n",
    ">`(batch_size, number_of_features, sequence_length)`.\n",
    "\n",
    "\n",
    ">**Instruction** : <br>\n",
    "Use `transpose` function in `data_module.py` to transpose the suitable input data for CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dict_covid , test_data_dict_covid = data_module.transpose(train_data_dict_covid,\n",
    "                                                                     test_data_dict_covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.sanity_check(train_data_dict_covid , test_data_dict_covid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Iterator\n",
    "Iterator is created to separate the data into several batches to fasten the training process\n",
    ">**Instruction** : <br>\n",
    "Use `data_module.iterator` to create data iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "train_iter_covid , test_iter_covid = data_module.iterator(train_data_dict_covid ,\n",
    "                                                          test_data_dict_covid,\n",
    "                                                          batch_size = batch_size_covid)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Model\n",
    "\n",
    ">**Instruction** : <br>\n",
    "Input the model that you have configured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed\n",
    "torch.manual_seed(123)\n",
    "\n",
    "n_feature_covid = train_data_dict_covid['train_data_x_feature'].shape[1]\n",
    "### BEGIN SOLUTION\n",
    "# Input the attribute need by the model \n",
    "model_covid = CNN(n_feature = n_feature_covid,\n",
    "                  n_step = n_step_covid )\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "# Define the optimizer (Here we use Adam as our optimizer)\n",
    "### BEGIN SOLUTION\n",
    "optimizer_covid = torch.optim.Adam(model_covid.parameters(), lr=learning_rate_covid)\n",
    "### END SOLUTION\n",
    "\n",
    "# Define the loss function (Here we use MSE as the loss function)\n",
    "### BEGIN SOLUTION\n",
    "loss_fn_covid = nn.MSELoss()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length_covid = train_data_dict_covid['train_data_x_feature'].shape[2]\n",
    "\n",
    "# batch size ,input_dim ,seq_length\n",
    "inputs = torch.zeros((batch_size_covid,\n",
    "                      n_feature_covid ,\n",
    "                      seq_length_covid),dtype=torch.float) \n",
    "\n",
    "print(summary(model_covid,inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# Xavier weight intialization\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        \n",
    "model_covid.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 : Training\n",
    ">**Instruction** : <br>\n",
    "Use `deep_learning_module.training` to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed\n",
    "torch.manual_seed(123)\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "# Start training \n",
    "train_loss_covid,val_loss_covid = deep_learning_module.training(num_epochs= num_epochs_covid ,\n",
    "                                                    train_iter = train_iter_covid,\n",
    "                                                    test_iter = test_iter_covid ,\n",
    "                                                    optimizer = optimizer_covid,\n",
    "                                                    loss_fn = loss_fn_covid,\n",
    "                                                    model = model_covid)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 : Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Learning Curve \n",
    "### BEGIN SOLUTION\n",
    "data_module.learning_curve(num_epochs = num_epochs_covid,\n",
    "                           train_loss = train_loss_covid ,\n",
    "                           val_loss = val_loss_covid)\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 : Evaluation\n",
    "This section is to inference the model by feeding in testing data, determining the output forecast values and calculating the RMSE. For this exercise, use the function in `data_module` to run in each section.\n",
    "\n",
    "It consists of 4 sections :\n",
    "\n",
    "Section 1 : Feed in the train and test data to the model <br>\n",
    "Section 2 : Reshape both to the original data dimension <br> \n",
    "Section 3 : Invert the scaling back to the original data value <br>\n",
    "Section 4 : Calculate the RMSE of train and test data\n",
    "\n",
    ">**Instruction** : <br>\n",
    "Complete each section with the function in `data_module.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1 : Make predictions\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "with torch.no_grad():\n",
    "    y_train_prediction_covid = model_covid(train_data_dict_covid['train_data_x_feature'])\n",
    "    y_test_prediction_covid = model_covid(test_data_dict_covid['test_data_x_feature'])\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign evaluation key\n",
    "### BEGIN SOLUTION\n",
    "prediction_covid , output_covid = data_module.key_assign_evaluation(y_train_prediction_covid,\n",
    "                                                                    y_test_prediction_covid,\n",
    "                                                                    train_data_dict_covid,\n",
    "                                                                    test_data_dict_covid)\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "# Section 2 : Reshape data\n",
    "### BEGIN SOLUTION\n",
    "# Squeeze the output dimension\n",
    "output_data_covid = data_module.squeeze_dimension(output_covid)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.sanity_check(data_1 = output_data_covid,data_2 = {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3 : Invert the scaling back to orignal data value\n",
    "### BEGIN SOLUTION\n",
    "scaler_covid_output = scaler_covid[list(scaler_covid)[-1]]\n",
    "prediction_covid = data_module.inverse_scaler(prediction_covid,scaler_covid_output)\n",
    "output_data_covid  = data_module.inverse_scaler(output_data_covid ,scaler_covid_output)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.rint` is used to round our data to integer since the death cases should be an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_covid['test_data_prediction'] = np.rint(prediction_covid['test_data_prediction'])\n",
    "output_data_covid['test_data_output'] =  np.rint(output_data_covid['test_data_output']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the forecast value\n",
    "### BEGIN SOLUTION\n",
    "data_module.list_forecast_value(output_data_covid,prediction_covid) \n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate root mean squared error\n",
    "### BEGIN SOLUTION\n",
    "trainScore_covid,testScore_covid = data_module.rmse(prediction_covid,output_data_covid)\n",
    "print('Train Score: %.2f RMSE' % (trainScore_covid))\n",
    "print('Test Score: %.2f RMSE' % (testScore_covid))\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 : Forecast Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.multi_step_plot(original_test_data = test_data_covid[\"Deaths\"],\n",
    "                            after_sequence_test_data = output_data_covid,\n",
    "                            forecast_data = prediction_covid,\n",
    "                            test_time = test_time_covid,\n",
    "                            window_size = window_size_covid,\n",
    "                            n_step = n_step_covid,\n",
    "                            details={},\n",
    "                            original_plot=True,\n",
    "                            multivariate = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this tutorial you should have learnt:\n",
    "\n",
    "1. The flow of using CNN to perform multivariate input, univariate output multi-step forecasting.<br>\n",
    "\n",
    "Congratulations, that concludes this lesson.<br>\n",
    "\n",
    "1. ~~*[04 - CNN_Univariate_SingleStep]*~~ *Complete*\n",
    "2. ~~*[04 - CNN_Univariate_MultiStep]*~~*Complete*\n",
    "3. ~~*[04 - CNN_Multivariate_Univariate_SingleStep]*~~*Complete*\n",
    "4. ~~*[04 - CNN_Multivariate_Univariate_MultiStep]*~~*Complete*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "1. [Deep Learning for Time Series Forecasting (Predict the Future with MLPs,CNNs and LSTMs in Python) , Jason Brownlee](https://machinelearningmastery.com/deep-learning-for-time-series-forecasting/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
