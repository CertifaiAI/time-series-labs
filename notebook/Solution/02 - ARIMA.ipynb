{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "> **Copyright &copy; 2020 CertifAI Sdn. Bhd.**<br>\n",
    " **Copyright &copy; 2021 CertifAI Sdn. Bhd.**<br>\n",
    " <br>\n",
    "This program and the accompanying materials are made available under the\n",
    "terms of the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \\\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n",
    "WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n",
    "License for the specific language governing permissions and limitations\n",
    "under the License. <br>\n",
    "<br>**SPDX-License-Identifier: Apache-2.0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airpassengers = pd.read_csv('../../datasets/decomposition/AirPassengers.csv')\n",
    "\n",
    "airpassengers_series = pd.Series(airpassengers['#Passengers'].values, \n",
    "                            index = pd.date_range('1949-01', periods = len(airpassengers), freq='M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(airpassengers_series)\n",
    "plt.title('airpassengers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many techniques (logarithm, exponential, de-trending, differencing) that can be used to transform non-stationary series into stationary.\n",
    "\n",
    "The choice of technique to be used depends on the pattern of our time series.\n",
    "\n",
    "Since we have a series with increment variance, logarithm transformation can be use to smooth out the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airpassengers_log = np.log(airpassengers_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16, 4))\n",
    "\n",
    "ax1.plot(airpassengers_series)\n",
    "ax1.set_title('original series')\n",
    "\n",
    "ax2.plot(airpassengers_log)\n",
    "ax2.set_title('log transformation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airpassengers_diff = airpassengers_log.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16, 4))\n",
    "\n",
    "ax1.plot(airpassengers_log)\n",
    "ax1.set_title('log transformation')\n",
    "\n",
    "ax2.plot(airpassengers_diff)\n",
    "ax2.set_title('differencing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16, 4))\n",
    "\n",
    "ax1.plot(airpassengers_series, label = 'raw data')\n",
    "ax1.plot(airpassengers_series.rolling(window=12).mean(), label=\"rolling mean\");\n",
    "ax1.plot(airpassengers_series.rolling(window=12).std(), label=\"rolling var\");\n",
    "ax1.set_title('original series')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(airpassengers_diff, label = 'transformed data')\n",
    "ax2.plot(airpassengers_diff.rolling(window=12).mean(), label=\"rolling mean\");\n",
    "ax2.plot(airpassengers_diff.rolling(window=12).std(), label=\"rolling var\");\n",
    "ax2.set_title('stationary series')\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented Dickey-Fuller Test (ADF)\n",
    "\n",
    "Unit roots are a cause for non-stationarity. Being a type of unit root test, ADF Test will determine if a unit root is present.\n",
    "\n",
    "A time series is considered stationary if a single shift in time doesnâ€™t change the time series statistical properties, in which case unit root does not exist.\n",
    "\n",
    "The Null and Alternate hypothesis of the Augmented Dickey-Fuller Test is defined as follows:\n",
    "- Null Hypothesis states there is a presence of a unit root.\n",
    "- Alternate Hypothesis states there is no unit root present. In other words, stationarity exists.\n",
    "\n",
    "https://machinelearningmastery.com/time-series-data-stationary-python/\n",
    "\n",
    "http://www.insightsbot.com/augmented-dickey-fuller-test-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_adf_result(adf_result):\n",
    "    df_results = pd.Series(adf_result[0:4], index=['ADF Test Statistic','P-Value','# Lags Used','# Observations Used'])\n",
    "    \n",
    "    for key, value in adf_result[4].items():\n",
    "        df_results['Critical Value (%s)'% key] = value\n",
    "    print('Augmented Dickey-Fuller Test Results:')\n",
    "    print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "result = adfuller(airpassengers_series, maxlag=12)\n",
    "print_adf_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = adfuller(airpassengers_diff[1:], maxlag=12)\n",
    "print_adf_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Stationary using Autocorrelation Function (ACF)\n",
    "\n",
    "http://rstudio-pubs-static.s3.amazonaws.com/311446_08b00d63cc794e158b1f4763eb70d43a.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "# from statsmodels.graphics.gofplots import qqplot\n",
    "# from scipy.stats import probplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16, 4))\n",
    "\n",
    "plot_acf(airpassengers_series, ax1)\n",
    "ax1.set_title('ACF of original series')\n",
    "\n",
    "plot_acf(airpassengers_diff[1:], ax2)\n",
    "ax2.set_title('ACF of differenced series')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax3, ax4) = plt.subplots(1,2, figsize=(16, 4))\n",
    "\n",
    "plot_pacf(airpassengers_series, ax3)\n",
    "ax3.set_title('PACF of original series')\n",
    "\n",
    "plot_pacf(airpassengers_diff[1:], ax4)\n",
    "ax4.set_title('PACF of differenced series')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "\n",
    "airpassengers_train = airpassengers_series[:-24]\n",
    "airpassengers_test = airpassengers_series[-24:]\n",
    "\n",
    "airpassengers_log_train = airpassengers_log[:-24]\n",
    "airpassengers_log_test = airpassengers_log[-24:]\n",
    "\n",
    "airpassengers_diff_train = airpassengers_diff[:-24]\n",
    "airpassengers_diff_test = airpassengers_diff[-24:]\n",
    "\n",
    "ses = SimpleExpSmoothing(airpassengers_diff_train[1:])\n",
    "ses = ses.fit()\n",
    "\n",
    "ses_forecast = ses.forecast(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(airpassengers_diff_train)\n",
    "plt.plot(ses_forecast)\n",
    "plt.title('forecast for next 24 month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_forecast[0] = ses_forecast[0] + airpassengers_log_train[-1]\n",
    "ses_forecast_inv_diff = ses_forecast.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_forecast_inv_log = np.exp(ses_forecast_inv_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16, 4))\n",
    "\n",
    "ax1.plot(airpassengers_log_train)\n",
    "ax1.plot(airpassengers_log_test)\n",
    "ax1.plot(ses_forecast_inv_diff)\n",
    "ax1.set_title('inverse differencing')\n",
    "\n",
    "ax2.plot(airpassengers_train)\n",
    "ax2.plot(airpassengers_test)\n",
    "ax2.plot(ses_forecast_inv_log)\n",
    "ax2.set_title('inverse log transformation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA\n",
    "\n",
    "ARIMA is stand for Autoregressive Integrated Moving Average. The integrated refers to differencing hence it allow the model to support series with trend.\n",
    "\n",
    "ARIMA expects data that is either not seasonal or has the seasonal component removed, thus we can perform seasonal differencing to eliminate the seasonality in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airpassengers_season_diff_train = airpassengers_train.diff(12)\n",
    "\n",
    "plt.plot(airpassengers_season_diff_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax5, ax6) = plt.subplots(1,2, figsize=(16, 4))\n",
    "\n",
    "plot_acf(airpassengers_season_diff_train.dropna(), ax5)\n",
    "ax3.set_title('ACF of differenced season seriess')\n",
    "\n",
    "plot_pacf(airpassengers_season_diff_train.dropna(), ax6)\n",
    "ax4.set_title('PACF of differenced season series')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Find d parameter for ARIMA\n",
    "find_d = ARIMA(airpassengers_season_diff_train.dropna(), order=(0,0,0)).fit()\n",
    "find_d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima = ARIMA(airpassengers_season_diff_train.dropna(), order=(1,0,1)).fit()\n",
    "arima.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values under *coef* are the weights of the respective terms. \n",
    "\n",
    "AIC and BIC is to tell how good is the model. They are metrics that may be used to compare with other models. The lower the AIC, the better the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residuals\n",
    "\n",
    "Residuals are useful in checking whether a model has adequately captured the information in the data. A good forecasting method will yield residuals with the following properties:\n",
    "- The residuals are uncorrelated. If there are correlations between residuals, then there is information left in the residuals which should be used in computing forecasts.\n",
    "- The residuals have zero mean. If the residuals have a mean other than zero, then the forecasts are biased.\n",
    "- The residuals have constant variance.\n",
    "- The residuals are normally distributed.\n",
    "\n",
    "\n",
    "Any forecasting method that does not satisfy these properties can be improved. However, that does not mean that forecasting methods that satisfy these properties cannot be improved. It is possible to have several different forecasting methods for the same data set, all of which satisfy these properties. Checking these properties is important in order to see whether a method is using all of the available information, but it is not a good way to select a forecasting method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = pd.Series(arima.resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def check_residuals(series):\n",
    "    fig = plt.figure(figsize=(16, 8))    \n",
    "    gs = fig.add_gridspec(2,2)\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    ax1.plot(series)\n",
    "    ax1.set_title('residuals')\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[1,0])\n",
    "    plot_acf(series, ax=ax2, title='ACF')\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[1,1])\n",
    "    sns.kdeplot(series, ax=ax3)\n",
    "    ax3.set_title('density')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_residuals(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_forecast, se, conf = arima.forecast(24)\n",
    "\n",
    "arima_forecast = pd.Series(arima_forecast, index=airpassengers_test.index)\n",
    "lower_series = pd.Series(conf[:, 0], index=airpassengers_test.index)\n",
    "upper_series = pd.Series(conf[:, 1], index=airpassengers_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(airpassengers_season_diff_train, label='train')\n",
    "plt.plot(arima_forecast, label='forecast')\n",
    "\n",
    "plt.fill_between(lower_series.index, lower_series, upper_series, color='k', alpha=.15)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_differencing(orig_data, diff_data, interval):\n",
    "    output = orig_data[:interval].tolist()\n",
    "    for i in range(interval, len(diff_data)):\n",
    "        output.append(output[i-interval] + diff_data[i])\n",
    "    return output\n",
    "\n",
    "def inverse_differencing_forecast(orig_series, diff_series, forecast_series, interval):\n",
    "    series_merge = diff_series.append(forecast_series)\n",
    "    inverse_diff_series = pd.Series(inverse_differencing(orig_series, series_merge, interval), \n",
    "                                    index=series_merge.index)\n",
    "    return inverse_diff_series[-len(forecast_series):]\n",
    "\n",
    "def train_test_forecast_plot(train_series, test_series, forecast_series, lower_upper=None):\n",
    "    plt.plot(train_series, label = 'train')\n",
    "    plt.plot(test_series, label = 'test')\n",
    "    plt.plot(forecast_series, label = 'forecast')\n",
    "\n",
    "    if lower_upper is not None:\n",
    "        plt.fill_between(lower_upper[0].index, lower_upper[0], \n",
    "                     lower_upper[1], color='k', alpha=.15)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse differenced series back to original series\n",
    "airpassengers_forecast_series = inverse_differencing_forecast(airpassengers_train, airpassengers_season_diff_train, arima_forecast, 12)\n",
    "airpassengers_lower_series = inverse_differencing_forecast(airpassengers_train, airpassengers_season_diff_train, lower_series, 12)\n",
    "airpassengers_upper_series = inverse_differencing_forecast(airpassengers_train, airpassengers_season_diff_train, upper_series, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(airpassengers_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_forecast_plot(airpassengers_train, airpassengers_test, airpassengers_forecast_series, \n",
    "                         [airpassengers_lower_series, airpassengers_upper_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(airpassengers_test, airpassengers_forecast_series)\n",
    "print('Test MSE: ', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARIMA\n",
    "\n",
    "Seasonal Autoregressive Integrated Moving Average (SARIMA) is a method to forecast univariate time series with trend and seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax7, ax8) = plt.subplots(1,2, figsize=(16, 4))\n",
    "\n",
    "plot_acf(airpassengers_train, ax7)\n",
    "ax3.set_title('ACF of seasonal series')\n",
    "\n",
    "plot_pacf(airpassengers_train, ax8)\n",
    "ax4.set_title('PACF of seasonal series')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarimax = SARIMAX(airpassengers_train, order=(3,1,1), seasonal_order=(0,1,0,12)).fit()\n",
    "sarimax.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarimax.plot_diagnostics(figsize=(16, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarimax_forecast = sarimax.get_forecast(24)\n",
    "sarimax_forecast_conf_int = sarimax_forecast.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(airpassengers_train, label='train')\n",
    "plt.plot(airpassengers_test, label='test')\n",
    "plt.plot(sarimax_forecast.predicted_mean, label='forecast')\n",
    "\n",
    "\n",
    "plt.fill_between(sarimax_forecast_conf_int.index,\n",
    "                 sarimax_forecast_conf_int.iloc[:, 0],\n",
    "                 sarimax_forecast_conf_int.iloc[:, 1], color='k', alpha=.2)\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "\n",
    "Grid search is the process of performing exhaustive searching throughout a manually specified parameters in order to determine the optimal values for a given model.\n",
    "\n",
    "For example, ARIMA has the parameters p, d, and q. we can manually specify range of values for parameters p, d, q, and build models based on the all the combination of parameters in p, d, and q. The measurement for the models can be in-sample error (AIC, BIC), or out-sample error (MSE). Finally, the model with the lowest error will be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_p = [0,1,2,3,4,5]\n",
    "param_d = [0,1] # ARIMA only support two times of differencing\n",
    "param_q = [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_error, best_params, best_model = None, None, None\n",
    "\n",
    "for p in param_p:\n",
    "    for d in param_d:\n",
    "        for q in param_q:\n",
    "            try:\n",
    "                arima = ARIMA(airpassengers_season_diff_train.dropna(), order=(p,d,q)).fit()\n",
    "                if best_error is None or arima.aic < best_error:\n",
    "                    best_error = arima.aic\n",
    "                    best_params = (p,d,q)\n",
    "                    best_model = arima\n",
    "                print('ARIMA({},{},{}), AIC={}'.format(p,d,q, arima.aic))\n",
    "            except:\n",
    "                pass\n",
    "print('Best Error={}, Best Params={}'.format(best_error, best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_forecast, se, conf = best_model.forecast(24)\n",
    "\n",
    "arima_forecast = pd.Series(arima_forecast, index=airpassengers_test.index)\n",
    "lower_series = pd.Series(conf[:, 0], index=airpassengers_test.index)\n",
    "upper_series = pd.Series(conf[:, 1], index=airpassengers_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse differenced series back to original series\n",
    "airpassengers_forecast_series = inverse_differencing_forecast(airpassengers_train, airpassengers_season_diff_train, arima_forecast, 12)\n",
    "airpassengers_lower_series = inverse_differencing_forecast(airpassengers_train, airpassengers_season_diff_train, lower_series, 12)\n",
    "airpassengers_upper_series = inverse_differencing_forecast(airpassengers_train, airpassengers_season_diff_train, upper_series, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_forecast_plot(airpassengers_train, airpassengers_test, airpassengers_forecast_series, \n",
    "                         [airpassengers_lower_series, airpassengers_upper_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(airpassengers_test, airpassengers_forecast_series)\n",
    "print('Test MSE: ', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Arima\n",
    "\n",
    "Pyramid brings Râ€™s beloved `auto.arima` to Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "#scikit-learn version = 0.23.2\n",
    "\n",
    "\n",
    "auto_arima = pm.arima.auto_arima(airpassengers_train, m=12,\n",
    "                            trace=True, seasonal=True,\n",
    "                            error_action='ignore',  \n",
    "                            suppress_warnings=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_forecast = auto_arima.predict(n_periods=24)\n",
    "auto_arima_forecast_series = pd.Series(auto_arima_forecast, index=airpassengers_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_forecast_plot(airpassengers_train, airpassengers_test, auto_arima_forecast_series, \n",
    "                         [airpassengers_lower_series, airpassengers_upper_series])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run through a simple exercise of building ARIMA model for time series data analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks that you are required to perform are listed below as comments. Please insert your codes below the comment. An approximation of number of lines *n* is provided as a guideline to help you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Library and dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# load dataset\n",
    "df = pd.read_csv('../../datasets/others/furniture-sales.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial data \n",
    "df.head()\n",
    "\n",
    "# setting DateTimeIndex since there is a datetime object conveniently \n",
    "df.DATE = pd.to_datetime(df.DATE, infer_datetime_format=True)\n",
    "df = df.set_index(df.DATE)\n",
    "df = df.asfreq(\"MS\")\n",
    "\n",
    "# remove date column\n",
    "del df['DATE']\n",
    "\n",
    "# rename column\n",
    "df = df.rename(columns={'MRTSSM442USN': 'Furniture_Sales'})\n",
    "\n",
    "# convert to Series\n",
    "df = pd.Series(df.Furniture_Sales.values, index=df.index)\n",
    "\n",
    "# display current Series\n",
    "print(df.head())\n",
    "\n",
    "# just extract and analyse data until the year 2006\n",
    "df_subset = df.loc[:'2006']\n",
    "\n",
    "# please perform a splitting to convert into train and test dataset\n",
    "split_ratio = round(df_subset.shape[0]*0.8)\n",
    "df_train = df_subset.iloc[:split_ratio]\n",
    "df_test = df_subset.iloc[split_ratio:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a time plot\n",
    "df_train.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a lag plot for lag of 12\n",
    "pd.plotting.lag_plot(df_train, lag=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stationarity check of mean, variance and autocorrelation\n",
    "plt.plot(df_train, label='Furniture Sales')\n",
    "plt.plot(df_train.rolling(window=12).mean(), label='mean')\n",
    "plt.plot(df_train.rolling(window=12).std(), label='std')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform ADF test\n",
    "def print_adf_result(adf_result):\n",
    "    df_results = pd.Series(adf_result[0:4], index=['ADF Test Statistic','P-Value','# Lags Used','# Observations Used'])\n",
    "    \n",
    "    for key, value in adf_result[4].items():\n",
    "        df_results['Critical Value (%s)'% key] = value\n",
    "    print('Augmented Dickey-Fuller Test Results:')\n",
    "    print(df_results)\n",
    "    \n",
    "\n",
    "result = adfuller(df_train)\n",
    "print_adf_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, the time series is not stationary. We will perform some transformations for it to be stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasonal differencing \n",
    "df_train_seasonal_diff = df_train.diff(12)\n",
    "\n",
    "\n",
    "# display result after transformation\n",
    "df_train_seasonal_diff.dropna().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect stationarity using ADF after differecing\n",
    "result = adfuller(df_train_seasonal_diff.dropna())\n",
    "print_adf_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect ACF and PACF to determine the hyperparameter to be used for ARIMA\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16, 4))\n",
    "\n",
    "plot_acf(df_train_seasonal_diff.dropna(), ax1)\n",
    "ax1.set_title('ACF of differenced season series')\n",
    "\n",
    "plot_pacf(df_train_seasonal_diff.dropna(), ax2)\n",
    "ax2.set_title('PACF of differenced season series')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building ARIMA model\n",
    "arima = ARIMA(df_train_seasonal_diff.dropna(), order=(3, 0, 3)).fit()\n",
    "\n",
    "# display summary of model\n",
    "arima.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual analysis\n",
    "residuals = pd.Series(arima.resid)\n",
    "\n",
    "def check_residuals(series):\n",
    "    fig = plt.figure(figsize=(16, 8))    \n",
    "    gs = fig.add_gridspec(2,2)\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    ax1.plot(series)\n",
    "    ax1.set_title('residuals')\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[1,0])\n",
    "    plot_acf(series, ax=ax2, title='ACF')\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[1,1])\n",
    "    sns.kdeplot(series, ax=ax3)\n",
    "    ax3.set_title('density')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "check_residuals(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform forecast using the newly built ARIMA model\n",
    "arima_forecast, se, conf = arima.forecast(len(df_subset)-split_ratio)\n",
    "\n",
    "arima_forecast = pd.Series(arima_forecast, index=df_test.index)\n",
    "lower_series = pd.Series(conf[:, 0], index=df_test.index)\n",
    "upper_series = pd.Series(conf[:, 1], index=df_test.index)\n",
    "\n",
    "plt.plot(df_train_seasonal_diff, label='train')\n",
    "plt.plot(arima_forecast, label='forecast')\n",
    "\n",
    "plt.fill_between(lower_series.index, lower_series, upper_series, color='k', alpha=.15)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform inverse transformation\n",
    "def inverse_differencing(orig_data, diff_data, interval):\n",
    "    output = orig_data[:interval].tolist()\n",
    "    for i in range(interval, len(diff_data)):\n",
    "        output.append(output[i-interval] + diff_data[i])\n",
    "    return output\n",
    "\n",
    "def inverse_differencing_forecast(orig_series, diff_series, forecast_series, interval):\n",
    "    series_merge = diff_series.append(forecast_series)\n",
    "    inverse_diff_series = pd.Series(inverse_differencing(orig_series, series_merge, interval), \n",
    "                                    index=series_merge.index)\n",
    "    return inverse_diff_series[-len(forecast_series):]\n",
    "\n",
    "def train_test_forecast_plot(train_series, test_series, forecast_series, lower_upper=None):\n",
    "    plt.plot(train_series, label = 'train')\n",
    "    plt.plot(test_series, label = 'test')\n",
    "    plt.plot(forecast_series, label = 'forecast')\n",
    "\n",
    "    if lower_upper is not None:\n",
    "        plt.fill_between(lower_upper[0].index, lower_upper[0], \n",
    "                     lower_upper[1], color='k', alpha=.15)\n",
    "    plt.legend()\n",
    "    \n",
    "df_subset_forecast_series = inverse_differencing_forecast(df_train, df_train_seasonal_diff, arima_forecast, 12)\n",
    "df_subset_lower_series = inverse_differencing_forecast(df_train, df_train_seasonal_diff, lower_series, 12)\n",
    "df_subset_upper_series = inverse_differencing_forecast(df_train, df_train_seasonal_diff, upper_series, 12)\n",
    "\n",
    "train_test_forecast_plot(df_train, df_test, df_subset_forecast_series, \n",
    "                         [df_subset_lower_series, df_subset_upper_series])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "mse = mean_squared_error(df_test, df_subset_forecast_series)\n",
    "print('Test MSE: ', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. https://towardsdatascience.com/time-series-in-python-exponential-smoothing-and-arima-processes-2c67f2a52788"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
