{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Multi-Step LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data sequencing function \n",
    "def univariate_multi_step(sequence,window_size,n_multistep):\n",
    "    x, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "    # find the end of this pattern\n",
    "        end_ix = i + window_size\n",
    "        out_ix = end_ix+n_multistep\n",
    "        # check if we are beyond the sequence\n",
    "        if out_ix > len(sequence):\n",
    "            break\n",
    "    # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_ix]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x27e96a4c590>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_ratio = 0.70\n",
    "num_epochs = 30\n",
    "n_step = 2 \n",
    "\n",
    "#seed\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0,  10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120,\n",
       "       130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250,\n",
       "       260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380,\n",
       "       390])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Synthetic Data\n",
    "univariate_series = np.array([x for x in range(0, 400, 10)])\n",
    "print(univariate_series.shape)\n",
    "univariate_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data = round(len(univariate_series)*split_ratio)\n",
    "split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_shape\n",
      "(28,)\n",
      "test_data_shape\n",
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "#split data by indexing \n",
    "train_data = univariate_series[:split_data]\n",
    "test_data = univariate_series[split_data:]\n",
    "print(\"train_data_shape\")\n",
    "print(train_data.shape)\n",
    "print(\"test_data_shape\")\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_data_normalized = scaler.fit_transform(train_data.reshape(-1, 1))\n",
    "\n",
    "test_data_normalized = scaler.fit_transform(test_data.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape:(24, 3, 1) trainY shape:(24, 2, 1)\n",
      "\n",
      "testX shape:(8, 3, 1) testX shape:(8, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "trainX ,trainY =  univariate_multi_step(train_data_normalized,3,n_step)\n",
    "testX , testY = univariate_multi_step(test_data_normalized,3,n_step)\n",
    "print(f\"trainX shape:{trainX.shape} trainY shape:{trainY.shape}\\n\")\n",
    "print(f\"testX shape:{testX.shape} testX shape:{testY.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape:torch.Size([24, 3, 1]) trainY shape:torch.Size([24, 2, 1])\n",
      "\n",
      "testX shape:torch.Size([8, 3, 1]) testY shape:torch.Size([8, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "#transfrom to Pytorch tensor\n",
    "trainX = torch.as_tensor(trainX).float()\n",
    "trainY = torch.as_tensor(trainY).float()\n",
    "testX = torch.as_tensor(testX).float()\n",
    "testY = torch.as_tensor(testY).float()\n",
    "print(f\"trainX shape:{trainX.shape} trainY shape:{trainY.shape}\\n\")\n",
    "print(f\"testX shape:{testX.shape} testY shape:{testY.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features are now in the shape of torch.Size([24, 3, 1]) while labels are now in the shape of torch.Size([24, 2, 1])\n",
      "\n",
      "x-feature\n",
      "24 = total number of data \n",
      "3 = window size \n",
      "1 = number of time series\n",
      "\n",
      "y-label\n",
      "24 = number of data\n",
      "2 = number of step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features are now in the shape of {trainX.shape} while labels are now in the shape of {trainY.shape}\\n\")\n",
    "print(\"x-feature\\n\"+str(trainX.shape[0])+\" = total number of data \")\n",
    "print(str(trainX.shape[1])+\" = window size \")\n",
    "print(str(trainX.shape[2])+\" = number of time series\\n\")\n",
    "print(\"y-label\\n\"+str(trainY.shape[0])+\" = number of data\")\n",
    "print(str(trainY.shape[1])+\" = number of step\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanila LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "        def __init__(self, n_feature, hidden_dim, num_layers, output_dim):\n",
    "            super(LSTM, self).__init__()\n",
    "\n",
    "            self.n_feature = n_feature\n",
    "            # Hidden dimensions\n",
    "            self.hidden_dim = hidden_dim\n",
    "\n",
    "            # Number of hidden layers\n",
    "            self.num_layers = num_layers\n",
    "\n",
    "            # Building your LSTM\n",
    "            # batch_first=True causes input/output tensors to be of shape\n",
    "            # (batch_dim, seq_dim, feature_dim)\n",
    "            self.lstm = nn.LSTM(n_feature, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "            # Readout layer\n",
    "            self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            # Initialize hidden state with zeros\n",
    "            h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "            # Initialize cell state\n",
    "            c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "            # One time step\n",
    "            # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "            # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "            out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "            # Index hidden state of last time step\n",
    "            # out.size() --> 100, 28, 100\n",
    "            # out[:, -1, :] --> 100, 100 --> just want last time step hidden states!\n",
    "            out = self.fc(out[:, -1, :])\n",
    "            # out.size() --> 100, 10\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionalLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, n_feature, hidden_dim, num_layers, output_dim):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "\n",
    "        self.n_feature = n_feature\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Building your LSTM\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(n_feature, hidden_dim, num_layers, batch_first=True,bidirectional=True)\n",
    "\n",
    "        # Readout layer *2 for bidirectional LSTM\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arguments for LSTM model\n",
    "hidden_dim = 10\n",
    "number_of_time_series = 1 \n",
    "timestep = 2\n",
    "\n",
    "#1 for vanila LSTM , >1 is mean stacked LSTM\n",
    "num_layers = 1 \n",
    "\n",
    "#Vanila , Stacked LSTM\n",
    "model = LSTM(n_feature=number_of_time_series, hidden_dim=hidden_dim, output_dim=timestep, num_layers=num_layers)\n",
    "\n",
    "#Bidirectional LSTM\n",
    "# model = BidirectionalLSTM(n_feature=number_of_time_series, hidden_dim=hidden_dim, output_dim=timestep, num_layers=num_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function \n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "#optimiser\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 MSE:  0.2841896712779999\n",
      "Epoch  1 MSE:  0.27279722690582275\n",
      "Epoch  2 MSE:  0.26188135147094727\n",
      "Epoch  3 MSE:  0.2514563500881195\n",
      "Epoch  4 MSE:  0.24142096936702728\n",
      "Epoch  5 MSE:  0.23165695369243622\n",
      "Epoch  6 MSE:  0.22206814587116241\n",
      "Epoch  7 MSE:  0.21257181465625763\n",
      "Epoch  8 MSE:  0.20303982496261597\n",
      "Epoch  9 MSE:  0.19325660169124603\n",
      "Epoch  10 MSE:  0.18291497230529785\n",
      "Epoch  11 MSE:  0.1716640740633011\n",
      "Epoch  12 MSE:  0.15920329093933105\n",
      "Epoch  13 MSE:  0.14536152780056\n",
      "Epoch  14 MSE:  0.13013184070587158\n",
      "Epoch  15 MSE:  0.11367560178041458\n",
      "Epoch  16 MSE:  0.09631427377462387\n",
      "Epoch  17 MSE:  0.07851607352495193\n",
      "Epoch  18 MSE:  0.06088617444038391\n",
      "Epoch  19 MSE:  0.04417113587260246\n",
      "Epoch  20 MSE:  0.029273075982928276\n",
      "Epoch  21 MSE:  0.017233025282621384\n",
      "Epoch  22 MSE:  0.009126913733780384\n",
      "Epoch  23 MSE:  0.005811700597405434\n",
      "Epoch  24 MSE:  0.007445821072906256\n",
      "Epoch  25 MSE:  0.012896780855953693\n",
      "Epoch  26 MSE:  0.019637469202280045\n",
      "Epoch  27 MSE:  0.024817274883389473\n",
      "Epoch  28 MSE:  0.026726530864834785\n",
      "Epoch  29 MSE:  0.02522101067006588\n"
     ]
    }
   ],
   "source": [
    "for t in range(num_epochs):\n",
    "    # Initialise hidden state\n",
    "#     Don't do this if you want your LSTM to be stateful\n",
    "#     model.hidden = model.init_hidden()\n",
    "\n",
    "    # Forward pass\n",
    "    y_train_pred = model(trainX)\n",
    "    \n",
    "    #Reshape to perform MSE \n",
    "    y_train_pred=torch.reshape(y_train_pred,(trainY.shape[0],trainY.shape[1],1))\n",
    "\n",
    "    loss = loss_fn(y_train_pred, trainY)\n",
    "    print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "\n",
    "    # Zero out gradient, else they will accumulate between epochs\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_test_pred = model(testX)\n",
    "\n",
    "#Reshape to original data\n",
    "y_train_pred = torch.reshape(y_train_pred,(y_train_pred.shape[0],y_train_pred.shape[1]))\n",
    "trainY = torch.reshape(trainY,(trainY.shape[0],trainY.shape[1]))\n",
    "y_test_pred = torch.reshape(y_test_pred,(y_test_pred.shape[0],y_test_pred.shape[1]))\n",
    "testY = torch.reshape(testY,(testY.shape[0],testY.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Invert predictions\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred.detach().numpy())\n",
    "y_train = scaler.inverse_transform(trainY.detach().numpy())\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred.detach().numpy())\n",
    "y_test = scaler.inverse_transform(testY.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y-test\t\t\t\ty-predict\n",
      "[310. 320.]\t\t[289.47516 288.94534]\n",
      "[320. 330.]\t\t[299.89438 298.6619 ]\n",
      "[330. 340.]\t\t[313.38794 311.63916]\n",
      "[340. 350.]\t\t[329.2237  327.36945]\n",
      "[350. 360.]\t\t[345.31842 343.9561 ]\n",
      "[360. 370.]\t\t[359.2459  359.01337]\n",
      "[370. 380.]\t\t[369.6973  371.06735]\n",
      "[380. 390.]\t\t[376.79083 379.96777]\n"
     ]
    }
   ],
   "source": [
    "print(\"y-test\\t\\t\\t\\ty-predict\")\n",
    "for i in range(len(y_test_pred)):\n",
    "    print(f\"{y_test[i]}\\t\\t{y_test_pred[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test_shape : (8, 2)\n",
      "y_test_pred_shape : (8, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_test_shape : {y_test.shape}\")\n",
    "print(f\"y_test_pred_shape : {y_test_pred.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 8.26 RMSE\n",
      "Test Score: 12.50 RMSE\n"
     ]
    }
   ],
   "source": [
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(y_train[:,0], y_train_pred[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(y_test[:,0], y_test_pred[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise for Univariate (Solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x27e96a4c590>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter\n",
    "num_epochs_shampoo = 100\n",
    "split_ratio = 0.70\n",
    "n_step = 2\n",
    "#Hidden Layer for LSTM\n",
    "hidden_dim = 32\n",
    "\n",
    "#seed\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    266.0\n",
       "1    145.9\n",
       "2    183.1\n",
       "3    119.3\n",
       "4    180.3\n",
       "Name: sales, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shampoo = pd.read_csv('../datasets/others/shampoo-sales.csv')\n",
    "shampoo_ts =shampoo['sales']\n",
    "shampoo_ts.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split data by indexing \n",
    "split_data = round(len(shampoo_ts)*split_ratio)\n",
    "split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_shampoo_shape\n",
      "(25,)\n",
      "test_data_shampoo_shape\n",
      "(11,)\n"
     ]
    }
   ],
   "source": [
    "train_data_shampoo = shampoo_ts[:split_data]\n",
    "test_data_shampoo = shampoo_ts[split_data:]\n",
    "print(\"train_data_shampoo_shape\")\n",
    "print(train_data_shampoo.shape)\n",
    "print(\"test_data_shampoo_shape\")\n",
    "print(test_data_shampoo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.82401588],\n",
       "       [-0.57790275],\n",
       "       [-1.        ],\n",
       "       [-0.59642739],\n",
       "       [-0.67449553]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Normalization\n",
    "\n",
    "#Reshape before normalize\n",
    "train_data_shampoo = train_data_shampoo.values.reshape(-1, 1)\n",
    "test_data_shampoo = test_data_shampoo.values.reshape((-1, 1))\n",
    "\n",
    "#Build Scaler\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_data_normalized_shampoo = scaler.fit_transform(train_data_shampoo)\n",
    "\n",
    "test_data_normalized_shampoo = scaler.fit_transform(test_data_shampoo)\n",
    "train_data_normalized_shampoo[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape:(22, 2, 1) trainY shape:(22, 2, 1)\n",
      "\n",
      "testX shape:(8, 2, 1) testY shape:(8, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "#Data Sequencing \n",
    "trainX_shampoo ,trainY_shampoo =  univariate_multi_step(train_data_normalized_shampoo,2,n_step)\n",
    "testX_shampoo , testY_shampoo = univariate_multi_step(test_data_normalized_shampoo,2,n_step)\n",
    "print(f\"trainX shape:{trainX_shampoo.shape} trainY shape:{trainY_shampoo.shape}\\n\")\n",
    "print(f\"testX shape:{testX_shampoo.shape} testY shape:{testY_shampoo.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape:torch.Size([22, 2, 1]) trainY shape:torch.Size([22, 2, 1])\n",
      "\n",
      "testX shape:torch.Size([8, 2, 1]) testX shape:torch.Size([8, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "#Transfrom numpy to Pytorch tensor\n",
    "trainX_shampoo = torch.as_tensor(trainX_shampoo).float()\n",
    "trainY_shampoo = torch.as_tensor(trainY_shampoo).float()\n",
    "testX_shampoo = torch.as_tensor(testX_shampoo).float()\n",
    "testY_shampoo = torch.as_tensor(testY_shampoo).float()\n",
    "print(f\"trainX shape:{trainX_shampoo.shape} trainY shape:{trainY_shampoo.shape}\\n\")\n",
    "print(f\"testX shape:{testX_shampoo.shape} testX shape:{testY_shampoo.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BidirectionalLSTM(\n",
       "  (lstm): LSTM(1, 32, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Arguments for LSTM model\n",
    "number_of_time_series = 1 \n",
    "timestep = 2\n",
    "output_dim =1 \n",
    "#1 for vanila LSTM , >1 is mean stacked LSTM\n",
    "num_layers = 1\n",
    "\n",
    "#Vanila ,Stacked LSTM\n",
    "# model_shampoo = LSTM(n_feature=number_of_time_series, hidden_dim=hidden_dim, output_dim=timestep, num_layers=num_layers)\n",
    "\n",
    "#Bidirectional LSTM\n",
    "model_shampoo = BidirectionalLSTM(n_feature=number_of_time_series, hidden_dim=hidden_dim, output_dim=timestep, num_layers=num_layers)\n",
    "model_shampoo.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_shampoo = torch.nn.MSELoss()\n",
    "\n",
    "optimiser_shampoo = torch.optim.Adam(model_shampoo.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 MSE:  0.31683558225631714\n",
      "Epoch  1 MSE:  0.28915512561798096\n",
      "Epoch  2 MSE:  0.26710045337677\n",
      "Epoch  3 MSE:  0.24960164725780487\n",
      "Epoch  4 MSE:  0.23722191154956818\n",
      "Epoch  5 MSE:  0.23146137595176697\n",
      "Epoch  6 MSE:  0.23219609260559082\n",
      "Epoch  7 MSE:  0.23401685059070587\n",
      "Epoch  8 MSE:  0.23180030286312103\n",
      "Epoch  9 MSE:  0.22552178800106049\n",
      "Epoch  10 MSE:  0.21760624647140503\n",
      "Epoch  11 MSE:  0.21034663915634155\n",
      "Epoch  12 MSE:  0.20492471754550934\n",
      "Epoch  13 MSE:  0.2013656198978424\n",
      "Epoch  14 MSE:  0.19887572526931763\n",
      "Epoch  15 MSE:  0.19627250730991364\n",
      "Epoch  16 MSE:  0.19260649383068085\n",
      "Epoch  17 MSE:  0.18782959878444672\n",
      "Epoch  18 MSE:  0.18294648826122284\n",
      "Epoch  19 MSE:  0.17950576543807983\n",
      "Epoch  20 MSE:  0.17850029468536377\n",
      "Epoch  21 MSE:  0.1790970265865326\n",
      "Epoch  22 MSE:  0.1791568100452423\n",
      "Epoch  23 MSE:  0.17787708342075348\n",
      "Epoch  24 MSE:  0.17662560939788818\n",
      "Epoch  25 MSE:  0.17686747014522552\n",
      "Epoch  26 MSE:  0.17790760099887848\n",
      "Epoch  27 MSE:  0.17781467735767365\n",
      "Epoch  28 MSE:  0.17615672945976257\n",
      "Epoch  29 MSE:  0.1739915907382965\n",
      "Epoch  30 MSE:  0.17235711216926575\n",
      "Epoch  31 MSE:  0.1714048832654953\n",
      "Epoch  32 MSE:  0.1706501543521881\n",
      "Epoch  33 MSE:  0.16976624727249146\n",
      "Epoch  34 MSE:  0.16891293227672577\n",
      "Epoch  35 MSE:  0.1684102565050125\n",
      "Epoch  36 MSE:  0.16834817826747894\n",
      "Epoch  37 MSE:  0.16852539777755737\n",
      "Epoch  38 MSE:  0.1686467081308365\n",
      "Epoch  39 MSE:  0.16853564977645874\n",
      "Epoch  40 MSE:  0.16820921003818512\n",
      "Epoch  41 MSE:  0.1678093820810318\n",
      "Epoch  42 MSE:  0.16746945679187775\n",
      "Epoch  43 MSE:  0.16721197962760925\n",
      "Epoch  44 MSE:  0.16694995760917664\n",
      "Epoch  45 MSE:  0.16658632457256317\n",
      "Epoch  46 MSE:  0.1661158949136734\n",
      "Epoch  47 MSE:  0.16562850773334503\n",
      "Epoch  48 MSE:  0.16521641612052917\n",
      "Epoch  49 MSE:  0.16488611698150635\n",
      "Epoch  50 MSE:  0.16455915570259094\n",
      "Epoch  51 MSE:  0.16415110230445862\n",
      "Epoch  52 MSE:  0.16364452242851257\n",
      "Epoch  53 MSE:  0.16309016942977905\n",
      "Epoch  54 MSE:  0.16254784166812897\n",
      "Epoch  55 MSE:  0.16203103959560394\n",
      "Epoch  56 MSE:  0.16150718927383423\n",
      "Epoch  57 MSE:  0.16094231605529785\n",
      "Epoch  58 MSE:  0.1603374481201172\n",
      "Epoch  59 MSE:  0.15972019731998444\n",
      "Epoch  60 MSE:  0.15910805761814117\n",
      "Epoch  61 MSE:  0.15848618745803833\n",
      "Epoch  62 MSE:  0.15782131254673004\n",
      "Epoch  63 MSE:  0.15709400177001953\n",
      "Epoch  64 MSE:  0.15631677210330963\n",
      "Epoch  65 MSE:  0.15552163124084473\n",
      "Epoch  66 MSE:  0.1547313779592514\n",
      "Epoch  67 MSE:  0.15394528210163116\n",
      "Epoch  68 MSE:  0.15315359830856323\n",
      "Epoch  69 MSE:  0.1523609757423401\n",
      "Epoch  70 MSE:  0.15158770978450775\n",
      "Epoch  71 MSE:  0.15084736049175262\n",
      "Epoch  72 MSE:  0.15013481676578522\n",
      "Epoch  73 MSE:  0.14944463968276978\n",
      "Epoch  74 MSE:  0.14879080653190613\n",
      "Epoch  75 MSE:  0.1481933295726776\n",
      "Epoch  76 MSE:  0.14765121042728424\n",
      "Epoch  77 MSE:  0.14714787900447845\n",
      "Epoch  78 MSE:  0.14667795598506927\n",
      "Epoch  79 MSE:  0.1462429016828537\n",
      "Epoch  80 MSE:  0.14582747220993042\n",
      "Epoch  81 MSE:  0.14541007578372955\n",
      "Epoch  82 MSE:  0.14498819410800934\n",
      "Epoch  83 MSE:  0.1445668786764145\n",
      "Epoch  84 MSE:  0.14413850009441376\n",
      "Epoch  85 MSE:  0.1436973363161087\n",
      "Epoch  86 MSE:  0.14325127005577087\n",
      "Epoch  87 MSE:  0.14280444383621216\n",
      "Epoch  88 MSE:  0.14235256612300873\n",
      "Epoch  89 MSE:  0.14189976453781128\n",
      "Epoch  90 MSE:  0.14145535230636597\n",
      "Epoch  91 MSE:  0.14101839065551758\n",
      "Epoch  92 MSE:  0.1405848115682602\n",
      "Epoch  93 MSE:  0.1401561200618744\n",
      "Epoch  94 MSE:  0.13972991704940796\n",
      "Epoch  95 MSE:  0.13929948210716248\n",
      "Epoch  96 MSE:  0.1388639360666275\n",
      "Epoch  97 MSE:  0.13842298090457916\n",
      "Epoch  98 MSE:  0.13796989619731903\n",
      "Epoch  99 MSE:  0.13750027120113373\n"
     ]
    }
   ],
   "source": [
    "for t in range(num_epochs_shampoo):\n",
    "    # Initialise hidden state\n",
    "    # Don't do this if you want your LSTM to be stateful\n",
    "    # model.hidden = model.init_hidden()\n",
    "\n",
    "    # Forward pass\n",
    "    y_train_pred_shampoo = model_shampoo(trainX_shampoo)\n",
    "    \n",
    "    #Reshape to perform MSE \n",
    "    y_train_pred_shampoo=torch.reshape(y_train_pred_shampoo,(trainY_shampoo.shape[0],trainY_shampoo.shape[1],1))\n",
    "    \n",
    "    loss_shampoo = loss_fn_shampoo(y_train_pred_shampoo, trainY_shampoo)\n",
    "    print(\"Epoch \", t, \"MSE: \", loss_shampoo.item())\n",
    "\n",
    "    # Zero out gradient, else they will accumulate between epochs\n",
    "    optimiser_shampoo.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss_shampoo.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimiser_shampoo.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_test_pred_shampoo = model_shampoo(testX_shampoo)\n",
    "\n",
    "#Reshape to original data\n",
    "y_train_pred_shampoo = torch.reshape(y_train_pred_shampoo,(y_train_pred_shampoo.shape[0],y_train_pred_shampoo.shape[1]))\n",
    "trainY_shampoo = torch.reshape(trainY_shampoo,(trainY_shampoo.shape[0],trainY_shampoo.shape[1]))\n",
    "y_test_pred_shampoo = torch.reshape(y_test_pred_shampoo,(y_test_pred_shampoo.shape[0],y_test_pred_shampoo.shape[1]))\n",
    "testY_shampoo = torch.reshape(testY_shampoo,(testY_shampoo.shape[0],testY_shampoo.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Invert predictions\n",
    "y_train_pred_shampoo = scaler.inverse_transform(y_train_pred_shampoo.detach().numpy())\n",
    "y_train_shampoo = scaler.inverse_transform(trainY_shampoo.detach().numpy())\n",
    "y_test_pred_shampoo = scaler.inverse_transform(y_test_pred_shampoo.detach().numpy())\n",
    "y_test_shampoo = scaler.inverse_transform(testY_shampoo.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_shampoo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y-test\t\t\ty-predict\n",
      "[439.3     401.30002]\t\t[421.08847 380.45023]\n",
      "[401.30002 437.4    ]\t\t[390.06454 398.96976]\n",
      "[437.4 575.5]\t\t[440.98538 463.0719 ]\n",
      "[575.5     407.60004]\t\t[428.87927 476.70508]\n",
      "[407.60004 682.     ]\t\t[476.0935  554.02496]\n",
      "[682.  475.3]\t\t[496.86307 401.22412]\n",
      "[475.3 581.3]\t\t[454.43622 527.33356]\n",
      "[581.3 646.9]\t\t[582.9071  532.88525]\n"
     ]
    }
   ],
   "source": [
    "print(\"y-test\\t\\t\\ty-predict\")\n",
    "for i in range(len(y_test_shampoo)):\n",
    "    print(f\"{y_test_shampoo[i]}\\t\\t{y_test_pred_shampoo[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test_shape : (8, 2)\n",
      "y_test_pred_shape : (8, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_test_shape : {y_test_shampoo.shape}\")   \n",
    "print(f\"y_test_pred_shape : {y_test_pred_shampoo.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 71.36 RMSE\n",
      "Test Score: 87.59 RMSE\n"
     ]
    }
   ],
   "source": [
    "#calculate root mean squared error\n",
    "trainScore_shampoo = math.sqrt(mean_squared_error(y_train_shampoo[:,0], y_train_pred_shampoo[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore_shampoo))\n",
    "testScore_shampoo = math.sqrt(mean_squared_error(y_test_shampoo[:,0], y_test_pred_shampoo[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore_shampoo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
