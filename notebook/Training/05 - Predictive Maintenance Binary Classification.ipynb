{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "> **Copyright &copy; 2020 CertifAI Sdn. Bhd.**<br>\n",
    " **Copyright &copy; 2021 CertifAI Sdn. Bhd.**<br>\n",
    " <br>\n",
    "This program and the accompanying materials are made available under the\n",
    "terms of the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \\\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n",
    "WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n",
    "License for the specific language governing permissions and limitations\n",
    "under the License. <br>\n",
    "<br>**SPDX-License-Identifier: Apache-2.0**> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 05 - Predictive Maintenance Binary Classification\n",
    " Predictive maintenance techniques are designed to help determine the condition of in-service equipment in order to\n",
    " estimate when maintenance should be performed. Predictive maintenance can be modeled in several ways,\n",
    " 1. Predict the Remaining Useful Life (RUL), or Time to Failure (TTF)\n",
    " 2. Predict if the asset will fail by given a certain time frame\n",
    " 3. Predict critical level of the asset by give a certain time frame\n",
    "\n",
    " This example we will look at the 2nd modeling strategy which is to predict weather the asset is going to fail. The target variable is \"Label1\".\n",
    " This label consist of 0 and 1. 0 means the assets is working fine and 1 means it require maintenance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading dataset (the first line has been written for you)\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important note is that the target variable needs to have balanced distribution for us to decide which metrics that is suitable to be used for model evaluation. So, we will check for distribution of target variable first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all features are useful for model building. We will first remove some unnecessary features before we proceed with model building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first remove the unnecessary columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we need to perform a train-test split so that we can use training dataset to build our model and have some data to evaluate it on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate out features and target variable\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data pre-processing : min-max normalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert our target variable to Torch Tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we need to split and prepare our dataset into format that is suitable for LSTM to be trained on. A helper function is written for you to perform this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processor(x_data, y_data, sequence_length):\n",
    "    \"\"\"\n",
    "    Helper function to sample sub-sequence of training data.\n",
    "    Input data must be numpy.\n",
    "    \"\"\"\n",
    "    x, y = [], []\n",
    "\n",
    "    # Fill the batch with random sequences of data\n",
    "    for i in range(x_data.shape[0] - sequence_length):\n",
    "\n",
    "        # copy the sequences of data starting at this index\n",
    "        x.append(x_data[i:i + sequence_length])\n",
    "        y.append(y_data[i + sequence_length])\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's change the data to a suitable format for model to train on\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us use the Dataset object to instantiate our dataset, this way it enables the use of len and indexing\n",
    "# This is the preferred way of preparing data in Pytorch\n",
    "class MaintenanceDataset(torch.utils.data.dataset.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.Tensor(x)\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we are ready to create iterator using DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-fb0522038292>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Or we can also just load one batch of the iterator as checking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Or we can also just load one batch of the iterator as checking\n",
    "next(iter(None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform some needed configuration for the model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just to configure model hyperparameters\n",
    "# Input configurations\n",
    "input_size = 20      # since one row has 20 features, we are reading one row at a time\n",
    "sequence_length = 30 # since there are 30 rows \n",
    "num_layers = 2       # stack 2 RNN together\n",
    "\n",
    "# Hyperparameter\n",
    "hidden_size = 128 # i think this is the number of hidden nodes\n",
    "num_classes = 2\n",
    "epochs = 5\n",
    "# batch_size = 200\n",
    "learning_rate = 0.001\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed) # to ensure reproducivility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's instantiate a model\n",
    "\n",
    "\n",
    "# let's set loss function and optimizer\n",
    "\n",
    "\n",
    "# finally we can start to train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate our model\n",
    "# Remember, we don't need to compute gradients as it is not required (and save some precious memory too!)\n",
    "with torch.no_grad():\n",
    "    None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please perform binary classification task using the same dataset and features but instead choose the target variable of \"label2\". Feel free to experiment with other features or use feature engineering techniques in case you have an adventurous spirit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# read dataset\n",
    "\n",
    "# initial data exploration\n",
    "\n",
    "# data pre-processing\n",
    "\n",
    "# model configuration\n",
    "\n",
    "# model building\n",
    "\n",
    "# model evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "1. https://jovian.ai/aakanksha-ns/shelter-outcome\n",
    "2. https://stackoverflow.com/questions/50307707/convert-pandas-dataframe-to-pytorch-tensor\n",
    "3. https://stackoverflow.com/questions/62208904/pytorch-custom-dataset-dataloader-returns-a-list-of-tensors-rather-than-tensor\n",
    "4. https://www.kaggle.com/c/predictive-maintenance (dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
