{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data sequencing function \n",
    "def univariate_single_step(sequence, window_size):\n",
    "    x, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "    # find the end of this pattern\n",
    "        end_ix = i + window_size\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "    # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(x), np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x22c72a2b590>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_ratio = 0.70\n",
    "num_epochs = 60\n",
    "\n",
    "\n",
    "#seed\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0,  10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120,\n",
       "       130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250,\n",
       "       260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380,\n",
       "       390])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Synthetic Data\n",
    "univariate_series = np.array([x for x in range(0, 400, 10)])\n",
    "print(univariate_series.shape)\n",
    "univariate_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data = round(len(univariate_series)*split_ratio)\n",
    "split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_shape\n",
      "(28,)\n",
      "test_data_shape\n",
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "#split data by indexing \n",
    "train_data = univariate_series[:split_data]\n",
    "test_data = univariate_series[split_data:]\n",
    "print(\"train_data_shape\")\n",
    "print(train_data.shape)\n",
    "print(\"test_data_shape\")\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_data_normalized = scaler.fit_transform(train_data.reshape(-1, 1))\n",
    "\n",
    "test_data_normalized = scaler.fit_transform(test_data.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape:(25, 3, 1) trainY shape:(25, 1)\n",
      "\n",
      "testX shape:(9, 3, 1) testX shape:(9, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "trainX ,trainY =  univariate_single_step(train_data_normalized,3)\n",
    "testX , testY = univariate_single_step(test_data_normalized,3)\n",
    "print(f\"trainX shape:{trainX.shape} trainY shape:{trainY.shape}\\n\")\n",
    "print(f\"testX shape:{testX.shape} testX shape:{testX.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape:torch.Size([25, 3, 1]) trainY shape:torch.Size([25, 1])\n",
      "\n",
      "testX shape:torch.Size([9, 3, 1]) testX shape:torch.Size([9, 3, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0000],\n",
       "         [-0.9259],\n",
       "         [-0.8519]],\n",
       "\n",
       "        [[-0.9259],\n",
       "         [-0.8519],\n",
       "         [-0.7778]],\n",
       "\n",
       "        [[-0.8519],\n",
       "         [-0.7778],\n",
       "         [-0.7037]],\n",
       "\n",
       "        [[-0.7778],\n",
       "         [-0.7037],\n",
       "         [-0.6296]],\n",
       "\n",
       "        [[-0.7037],\n",
       "         [-0.6296],\n",
       "         [-0.5556]],\n",
       "\n",
       "        [[-0.6296],\n",
       "         [-0.5556],\n",
       "         [-0.4815]],\n",
       "\n",
       "        [[-0.5556],\n",
       "         [-0.4815],\n",
       "         [-0.4074]],\n",
       "\n",
       "        [[-0.4815],\n",
       "         [-0.4074],\n",
       "         [-0.3333]],\n",
       "\n",
       "        [[-0.4074],\n",
       "         [-0.3333],\n",
       "         [-0.2593]],\n",
       "\n",
       "        [[-0.3333],\n",
       "         [-0.2593],\n",
       "         [-0.1852]],\n",
       "\n",
       "        [[-0.2593],\n",
       "         [-0.1852],\n",
       "         [-0.1111]],\n",
       "\n",
       "        [[-0.1852],\n",
       "         [-0.1111],\n",
       "         [-0.0370]],\n",
       "\n",
       "        [[-0.1111],\n",
       "         [-0.0370],\n",
       "         [ 0.0370]],\n",
       "\n",
       "        [[-0.0370],\n",
       "         [ 0.0370],\n",
       "         [ 0.1111]],\n",
       "\n",
       "        [[ 0.0370],\n",
       "         [ 0.1111],\n",
       "         [ 0.1852]],\n",
       "\n",
       "        [[ 0.1111],\n",
       "         [ 0.1852],\n",
       "         [ 0.2593]],\n",
       "\n",
       "        [[ 0.1852],\n",
       "         [ 0.2593],\n",
       "         [ 0.3333]],\n",
       "\n",
       "        [[ 0.2593],\n",
       "         [ 0.3333],\n",
       "         [ 0.4074]],\n",
       "\n",
       "        [[ 0.3333],\n",
       "         [ 0.4074],\n",
       "         [ 0.4815]],\n",
       "\n",
       "        [[ 0.4074],\n",
       "         [ 0.4815],\n",
       "         [ 0.5556]],\n",
       "\n",
       "        [[ 0.4815],\n",
       "         [ 0.5556],\n",
       "         [ 0.6296]],\n",
       "\n",
       "        [[ 0.5556],\n",
       "         [ 0.6296],\n",
       "         [ 0.7037]],\n",
       "\n",
       "        [[ 0.6296],\n",
       "         [ 0.7037],\n",
       "         [ 0.7778]],\n",
       "\n",
       "        [[ 0.7037],\n",
       "         [ 0.7778],\n",
       "         [ 0.8519]],\n",
       "\n",
       "        [[ 0.7778],\n",
       "         [ 0.8519],\n",
       "         [ 0.9259]]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transfrom to Pytorch tensor\n",
    "trainX = torch.as_tensor(trainX).float()\n",
    "trainY = torch.as_tensor(trainY).float()\n",
    "testX = torch.as_tensor(testX).float()\n",
    "testY = torch.as_tensor(testY).float()\n",
    "print(f\"trainX shape:{trainX.shape} trainY shape:{trainY.shape}\\n\")\n",
    "print(f\"testX shape:{testX.shape} testX shape:{testX.shape}\")\n",
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features are now in the shape of torch.Size([25, 3, 1]) while labels are now in the shape of torch.Size([25, 1])\n",
      "\n",
      "x-feature\n",
      "25 = total number of data \n",
      "3 = window size \n",
      "1 = number of time series\n",
      "\n",
      "y-label\n",
      "25 = number of data\n",
      "1 = number of step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features are now in the shape of {trainX.shape} while labels are now in the shape of {trainY.shape}\\n\")\n",
    "print(\"x-feature\\n\"+str(trainX.shape[0])+\" = total number of data \")\n",
    "print(str(trainX.shape[1])+\" = window size \")\n",
    "print(str(trainX.shape[2])+\" = number of time series\\n\")\n",
    "print(\"y-label\\n\"+str(trainY.shape[0])+\" = number of data\")\n",
    "print(str(trainY.shape[1])+\" = number of step\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model Configuration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanila LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "        def __init__(self, n_feature, hidden_dim, num_layers, output_dim):\n",
    "            super(LSTM, self).__init__()\n",
    "\n",
    "            self.n_feature = n_feature\n",
    "            # Hidden dimensions\n",
    "            self.hidden_dim = hidden_dim\n",
    "\n",
    "            # Number of hidden layers\n",
    "            self.num_layers = num_layers\n",
    "\n",
    "            # Building your LSTM\n",
    "            # batch_first=True causes input/output tensors to be of shape\n",
    "            # (batch_dim, seq_dim, feature_dim)\n",
    "            self.lstm = nn.LSTM(n_feature, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "            # Readout layer\n",
    "            self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            # Initialize hidden state with zeros\n",
    "            h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "            # Initialize cell state\n",
    "            c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "            # One time step\n",
    "            # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "            # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "            out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "            # Index hidden state of last time step\n",
    "            # out.size() --> 100, 28, 100\n",
    "            # out[:, -1, :] --> 100, 100 --> just want last time step hidden states!\n",
    "            out = self.fc(out[:, -1, :])\n",
    "            # out.size() --> 100, 10\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionalLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, n_feature, hidden_dim, num_layers, output_dim):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "\n",
    "        self.n_feature = n_feature\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Building your LSTM\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(n_feature, hidden_dim, num_layers, batch_first=True,bidirectional=True)\n",
    "\n",
    "        # Readout layer *2 for bidirectional LSTM\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers*2, x.shape(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.num_layers*2, x.shape(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(1, 10, num_layers=3, batch_first=True)\n",
       "  (fc): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Arguments for LSTM model\n",
    "hidden_dim = 10\n",
    "number_of_time_series = 1 \n",
    "timestep = 1\n",
    "output_dim =1 \n",
    "\n",
    "#1 for vanila LSTM , >1 is mean stacked LSTM\n",
    "num_layers = 3 \n",
    "\n",
    "#model for vanila ,stack\n",
    "model = LSTM(n_feature=number_of_time_series, hidden_dim=hidden_dim, output_dim=timestep, num_layers=num_layers)\n",
    "#model for bidirectional\n",
    "# model = BidirectionalLSTM(n_feature=number_of_time_series, hidden_dim=hidden_dim, output_dim=timestep, num_layers=num_layers)\n",
    "model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function \n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "#optimiser\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 MSE:  0.3688581585884094\n",
      "Epoch  1 MSE:  0.34376877546310425\n",
      "Epoch  2 MSE:  0.32158589363098145\n",
      "Epoch  3 MSE:  0.3028506338596344\n",
      "Epoch  4 MSE:  0.2886413633823395\n",
      "Epoch  5 MSE:  0.28067171573638916\n",
      "Epoch  6 MSE:  0.28030386567115784\n",
      "Epoch  7 MSE:  0.2850654721260071\n",
      "Epoch  8 MSE:  0.2872196435928345\n",
      "Epoch  9 MSE:  0.2835320234298706\n",
      "Epoch  10 MSE:  0.2761363387107849\n",
      "Epoch  11 MSE:  0.26781147718429565\n",
      "Epoch  12 MSE:  0.260130912065506\n",
      "Epoch  13 MSE:  0.25334447622299194\n",
      "Epoch  14 MSE:  0.24684424698352814\n",
      "Epoch  15 MSE:  0.23962406814098358\n",
      "Epoch  16 MSE:  0.23050367832183838\n",
      "Epoch  17 MSE:  0.2181830257177353\n",
      "Epoch  18 MSE:  0.20141609013080597\n",
      "Epoch  19 MSE:  0.17948806285858154\n",
      "Epoch  20 MSE:  0.15290845930576324\n",
      "Epoch  21 MSE:  0.12405817955732346\n",
      "Epoch  22 MSE:  0.09670815616846085\n",
      "Epoch  23 MSE:  0.07285042107105255\n",
      "Epoch  24 MSE:  0.0527329258620739\n",
      "Epoch  25 MSE:  0.037791356444358826\n",
      "Epoch  26 MSE:  0.029768405482172966\n",
      "Epoch  27 MSE:  0.030134662985801697\n",
      "Epoch  28 MSE:  0.03848864138126373\n",
      "Epoch  29 MSE:  0.04874783381819725\n",
      "Epoch  30 MSE:  0.05416718125343323\n",
      "Epoch  31 MSE:  0.0535103939473629\n",
      "Epoch  32 MSE:  0.048613741993904114\n",
      "Epoch  33 MSE:  0.04155438393354416\n",
      "Epoch  34 MSE:  0.03386692702770233\n",
      "Epoch  35 MSE:  0.026768388226628304\n",
      "Epoch  36 MSE:  0.02134101465344429\n",
      "Epoch  37 MSE:  0.018314329907298088\n",
      "Epoch  38 MSE:  0.017741568386554718\n",
      "Epoch  39 MSE:  0.018978117033839226\n",
      "Epoch  40 MSE:  0.021017014980316162\n",
      "Epoch  41 MSE:  0.022910771891474724\n",
      "Epoch  42 MSE:  0.024023842066526413\n",
      "Epoch  43 MSE:  0.02407350391149521\n",
      "Epoch  44 MSE:  0.023057997226715088\n",
      "Epoch  45 MSE:  0.021173197776079178\n",
      "Epoch  46 MSE:  0.018757672980427742\n",
      "Epoch  47 MSE:  0.016249705106019974\n",
      "Epoch  48 MSE:  0.014116542413830757\n",
      "Epoch  49 MSE:  0.012733190320432186\n",
      "Epoch  50 MSE:  0.012237433344125748\n",
      "Epoch  51 MSE:  0.012443571351468563\n",
      "Epoch  52 MSE:  0.0129057876765728\n",
      "Epoch  53 MSE:  0.01313201803714037\n",
      "Epoch  54 MSE:  0.012813390232622623\n",
      "Epoch  55 MSE:  0.0119162043556571\n",
      "Epoch  56 MSE:  0.010624988935887814\n",
      "Epoch  57 MSE:  0.009238485246896744\n",
      "Epoch  58 MSE:  0.00807321909815073\n",
      "Epoch  59 MSE:  0.0073529756627976894\n"
     ]
    }
   ],
   "source": [
    "for t in range(num_epochs):\n",
    "    # Initialise hidden state\n",
    "#     Don't do this if you want your LSTM to be stateful\n",
    "#     model.hidden = model.init_hidden()\n",
    "\n",
    "    # Forward pass\n",
    "    y_train_pred = model(trainX.float())\n",
    "    # print(\"after transform y_train_pred.shape\"+str(y_train_pred.shape))\n",
    "\n",
    "    loss = loss_fn(y_train_pred, trainY)\n",
    "    print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "\n",
    "    # Zero out gradient, else they will accumulate between epochs\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_test_pred = model(testX)\n",
    "\n",
    "#Reshape to original data\n",
    "y_train_pred = torch.reshape(y_train_pred,(y_train_pred.shape[0],y_train_pred.shape[1]))\n",
    "trainY = torch.reshape(trainY,(trainY.shape[0],trainY.shape[1]))\n",
    "y_test_pred = torch.reshape(y_test_pred,(y_test_pred.shape[0],y_test_pred.shape[1]))\n",
    "testY = torch.reshape(testY,(testY.shape[0],testY.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Invert predictions\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred.detach().numpy())\n",
    "y_train = scaler.inverse_transform(trainY.detach().numpy())\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred.detach().numpy())\n",
    "y_test = scaler.inverse_transform(testY.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test_shape : (9, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[310.],\n",
       "       [320.],\n",
       "       [330.],\n",
       "       [340.],\n",
       "       [350.],\n",
       "       [360.],\n",
       "       [370.],\n",
       "       [380.],\n",
       "       [390.]], dtype=float32)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"y_test_shape : {y_test.shape}\")\n",
    "y_test      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test_pred_shape : (9, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[303.18906],\n",
       "       [306.51974],\n",
       "       [312.10962],\n",
       "       [321.66388],\n",
       "       [335.0034 ],\n",
       "       [348.56177],\n",
       "       [359.56076],\n",
       "       [367.68277],\n",
       "       [373.56143]], dtype=float32)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"y_test_pred_shape : {y_test_pred.shape}\")\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 4.72 RMSE\n",
      "Test Score: 14.03 RMSE\n"
     ]
    }
   ],
   "source": [
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(y_train[:,0], y_train_pred[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(y_test[:,0], y_test_pred[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise for Univariate (Solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using LSTM to create a model that can prdict the sales of shampoo for last 3 month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    266.0\n",
       "1    145.9\n",
       "2    183.1\n",
       "3    119.3\n",
       "4    180.3\n",
       "dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shampoo = pd.read_csv('../datasets/others/shampoo-sales.csv')\n",
    "shampoo_ts = pd.Series(shampoo['sales'].values)\n",
    "shampoo_ts.head() \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_shape\n",
      "(20,)\n",
      "test_data_shape\n",
      "(20,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     266.0\n",
       "1     145.9\n",
       "2     183.1\n",
       "3     119.3\n",
       "4     180.3\n",
       "5     168.5\n",
       "6     231.8\n",
       "7     224.5\n",
       "8     192.8\n",
       "9     122.9\n",
       "10    336.5\n",
       "11    185.9\n",
       "12    194.3\n",
       "13    149.5\n",
       "14    210.1\n",
       "15    273.3\n",
       "dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split data by indexing \n",
    "split_data = 20\n",
    "train_data_shampoo = shampoo_ts[:-split_data]\n",
    "test_data_shampoo = shampoo_ts[-split_data:]\n",
    "print(\"train_data_shape\")\n",
    "print(train_data.shape)\n",
    "print(\"test_data_shape\")\n",
    "print(test_data.shape)\n",
    "train_data_shampoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-169-1ba81dd73b89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Data Normalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_data_normalized_shampoo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_shampoo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_data_normalized_shampoo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data_shampoo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\keras\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5138\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "#Data Normalization\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_data_normalized_shampoo = scaler.fit_transform(train_data_shampoo.reshape(-1, 1))\n",
    "\n",
    "test_data_normalized_shampoo = scaler.fit_transform(test_data_shampoo.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape:torch.Size([18, 2, 1]) trainY shape:torch.Size([18, 1])\n",
      "\n",
      "testX shape:torch.Size([18, 2, 1]) testX shape:torch.Size([18, 2, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0000],\n",
       "         [-0.8947]],\n",
       "\n",
       "        [[-0.8947],\n",
       "         [-0.7895]],\n",
       "\n",
       "        [[-0.7895],\n",
       "         [-0.6842]],\n",
       "\n",
       "        [[-0.6842],\n",
       "         [-0.5789]],\n",
       "\n",
       "        [[-0.5789],\n",
       "         [-0.4737]],\n",
       "\n",
       "        [[-0.4737],\n",
       "         [-0.3684]],\n",
       "\n",
       "        [[-0.3684],\n",
       "         [-0.2632]],\n",
       "\n",
       "        [[-0.2632],\n",
       "         [-0.1579]],\n",
       "\n",
       "        [[-0.1579],\n",
       "         [-0.0526]],\n",
       "\n",
       "        [[-0.0526],\n",
       "         [ 0.0526]],\n",
       "\n",
       "        [[ 0.0526],\n",
       "         [ 0.1579]],\n",
       "\n",
       "        [[ 0.1579],\n",
       "         [ 0.2632]],\n",
       "\n",
       "        [[ 0.2632],\n",
       "         [ 0.3684]],\n",
       "\n",
       "        [[ 0.3684],\n",
       "         [ 0.4737]],\n",
       "\n",
       "        [[ 0.4737],\n",
       "         [ 0.5789]],\n",
       "\n",
       "        [[ 0.5789],\n",
       "         [ 0.6842]],\n",
       "\n",
       "        [[ 0.6842],\n",
       "         [ 0.7895]],\n",
       "\n",
       "        [[ 0.7895],\n",
       "         [ 0.8947]]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Sequencing \n",
    "trainX_shampoo ,trainY_shampoo =  univariate_single_step(train_data_normalized_shampoo,2)\n",
    "testX_shampoo , testY_shampoo = univariate_single_step(test_data_normalized_shampoo,2)\n",
    "print(f\"trainX shape:{trainX.shape} trainY shape:{trainY.shape}\\n\")\n",
    "print(f\"testX shape:{testX.shape} testX shape:{testX.shape}\")\n",
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape:torch.Size([18, 2, 1]) trainY shape:torch.Size([18, 1])\n",
      "\n",
      "testX shape:torch.Size([18, 2, 1]) testX shape:torch.Size([18, 2, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0000],\n",
       "         [-0.8947]],\n",
       "\n",
       "        [[-0.8947],\n",
       "         [-0.7895]],\n",
       "\n",
       "        [[-0.7895],\n",
       "         [-0.6842]],\n",
       "\n",
       "        [[-0.6842],\n",
       "         [-0.5789]],\n",
       "\n",
       "        [[-0.5789],\n",
       "         [-0.4737]],\n",
       "\n",
       "        [[-0.4737],\n",
       "         [-0.3684]],\n",
       "\n",
       "        [[-0.3684],\n",
       "         [-0.2632]],\n",
       "\n",
       "        [[-0.2632],\n",
       "         [-0.1579]],\n",
       "\n",
       "        [[-0.1579],\n",
       "         [-0.0526]],\n",
       "\n",
       "        [[-0.0526],\n",
       "         [ 0.0526]],\n",
       "\n",
       "        [[ 0.0526],\n",
       "         [ 0.1579]],\n",
       "\n",
       "        [[ 0.1579],\n",
       "         [ 0.2632]],\n",
       "\n",
       "        [[ 0.2632],\n",
       "         [ 0.3684]],\n",
       "\n",
       "        [[ 0.3684],\n",
       "         [ 0.4737]],\n",
       "\n",
       "        [[ 0.4737],\n",
       "         [ 0.5789]],\n",
       "\n",
       "        [[ 0.5789],\n",
       "         [ 0.6842]],\n",
       "\n",
       "        [[ 0.6842],\n",
       "         [ 0.7895]],\n",
       "\n",
       "        [[ 0.7895],\n",
       "         [ 0.8947]]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transfrom to Pytorch tensor\n",
    "trainX_shampoo = torch.as_tensor(trainX_shampoo).float()\n",
    "trainY_shampoo = torch.as_tensor(trainY_shampoo).float()\n",
    "testX_shampoo = torch.as_tensor(testX_shampoo).float()\n",
    "testY_shampoo = torch.as_tensor(testY_shampoo).float()\n",
    "print(f\"trainX shape:{trainX.shape} trainY shape:{trainY.shape}\\n\")\n",
    "print(f\"testX shape:{testX.shape} testX shape:{testX.shape}\")\n",
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(1, 32, batch_first=True)\n",
       "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Arguments for LSTM model\n",
    "hidden_dim = 32\n",
    "number_of_time_series = 1 \n",
    "timestep = 1\n",
    "output_dim =1 \n",
    "#1 for vanila LSTM , >1 is mean stacked LSTM\n",
    "num_layers = 1\n",
    "\n",
    "#model for vanila ,stack\n",
    "model = LSTM(n_feature=number_of_time_series, hidden_dim=hidden_dim, output_dim=timestep, num_layers=num_layers)\n",
    "# model = BidirectionalLSTM(n_feature=number_of_time_series, hidden_dim=hidden_dim, output_dim=timestep, num_layers=num_layers)\n",
    "model.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 MSE:  0.30704465508461\n",
      "Epoch  1 MSE:  0.30704465508461\n",
      "Epoch  2 MSE:  0.30704465508461\n",
      "Epoch  3 MSE:  0.30704465508461\n",
      "Epoch  4 MSE:  0.30704465508461\n",
      "Epoch  5 MSE:  0.30704465508461\n",
      "Epoch  6 MSE:  0.30704465508461\n",
      "Epoch  7 MSE:  0.30704465508461\n",
      "Epoch  8 MSE:  0.30704465508461\n",
      "Epoch  9 MSE:  0.30704465508461\n",
      "Epoch  10 MSE:  0.30704465508461\n",
      "Epoch  11 MSE:  0.30704465508461\n",
      "Epoch  12 MSE:  0.30704465508461\n",
      "Epoch  13 MSE:  0.30704465508461\n",
      "Epoch  14 MSE:  0.30704465508461\n",
      "Epoch  15 MSE:  0.30704465508461\n",
      "Epoch  16 MSE:  0.30704465508461\n",
      "Epoch  17 MSE:  0.30704465508461\n",
      "Epoch  18 MSE:  0.30704465508461\n",
      "Epoch  19 MSE:  0.30704465508461\n",
      "Epoch  20 MSE:  0.30704465508461\n",
      "Epoch  21 MSE:  0.30704465508461\n",
      "Epoch  22 MSE:  0.30704465508461\n",
      "Epoch  23 MSE:  0.30704465508461\n",
      "Epoch  24 MSE:  0.30704465508461\n",
      "Epoch  25 MSE:  0.30704465508461\n",
      "Epoch  26 MSE:  0.30704465508461\n",
      "Epoch  27 MSE:  0.30704465508461\n",
      "Epoch  28 MSE:  0.30704465508461\n",
      "Epoch  29 MSE:  0.30704465508461\n",
      "Epoch  30 MSE:  0.30704465508461\n",
      "Epoch  31 MSE:  0.30704465508461\n",
      "Epoch  32 MSE:  0.30704465508461\n",
      "Epoch  33 MSE:  0.30704465508461\n",
      "Epoch  34 MSE:  0.30704465508461\n",
      "Epoch  35 MSE:  0.30704465508461\n",
      "Epoch  36 MSE:  0.30704465508461\n",
      "Epoch  37 MSE:  0.30704465508461\n",
      "Epoch  38 MSE:  0.30704465508461\n",
      "Epoch  39 MSE:  0.30704465508461\n",
      "Epoch  40 MSE:  0.30704465508461\n",
      "Epoch  41 MSE:  0.30704465508461\n",
      "Epoch  42 MSE:  0.30704465508461\n",
      "Epoch  43 MSE:  0.30704465508461\n",
      "Epoch  44 MSE:  0.30704465508461\n",
      "Epoch  45 MSE:  0.30704465508461\n",
      "Epoch  46 MSE:  0.30704465508461\n",
      "Epoch  47 MSE:  0.30704465508461\n",
      "Epoch  48 MSE:  0.30704465508461\n",
      "Epoch  49 MSE:  0.30704465508461\n",
      "Epoch  50 MSE:  0.30704465508461\n",
      "Epoch  51 MSE:  0.30704465508461\n",
      "Epoch  52 MSE:  0.30704465508461\n",
      "Epoch  53 MSE:  0.30704465508461\n",
      "Epoch  54 MSE:  0.30704465508461\n",
      "Epoch  55 MSE:  0.30704465508461\n",
      "Epoch  56 MSE:  0.30704465508461\n",
      "Epoch  57 MSE:  0.30704465508461\n",
      "Epoch  58 MSE:  0.30704465508461\n",
      "Epoch  59 MSE:  0.30704465508461\n"
     ]
    }
   ],
   "source": [
    "for t in range(num_epochs):\n",
    "    # Initialise hidden state\n",
    "    # Don't do this if you want your LSTM to be stateful\n",
    "    # model.hidden = model.init_hidden()\n",
    "\n",
    "    # Forward pass\n",
    "    y_train_pred_shampoo = model(trainX_shampoo.float())\n",
    "    # print(\"after transform y_train_pred.shape\"+str(y_train_pred.shape))\n",
    "\n",
    "    loss = loss_fn(y_train_pred_shampoo, trainY_shampoo)\n",
    "    print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "\n",
    "    # Zero out gradient, else they will accumulate between epochs\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_test_pred_shampoo = model(testX_shampoo)\n",
    "\n",
    "#Reshape to original data\n",
    "y_train_pred_shampoo = torch.reshape(y_train_pred_shampoo,(y_train_pred_shampoo.shape[0],y_train_pred_shampoo.shape[1]))\n",
    "trainY_shampoo = torch.reshape(trainY_shampoo,(trainY_shampoo.shape[0],trainY_shampoo.shape[1]))\n",
    "y_test_pred_shampoo = torch.reshape(y_test_pred_shampoo,(y_test_pred_shampoo.shape[0],y_test_pred_shampoo.shape[1]))\n",
    "testY_shampoo = torch.reshape(testY,(testY_shampoo.shape[0],testY_shampoo.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-74a9af235641>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Invert predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_train_pred_shampoo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_pred_shampoo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_train_shampoo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainY_shampoo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_test_pred_shampoo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_pred_shampoo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_test_shampoo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestY_shampoo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    425\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \"\"\"\n\u001b[1;32m--> 427\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         X = check_array(X, copy=self.copy, dtype=FLOAT_DTYPES,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1019\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "#Invert predictions\n",
    "y_train_pred_shampoo = scaler.inverse_transform(y_train_pred_shampoo.detach().numpy())\n",
    "y_train_shampoo = scaler.inverse_transform(trainY_shampoo.detach().numpy())\n",
    "y_test_pred_shampoo = scaler.inverse_transform(y_test_pred_shampoo.detach().numpy())\n",
    "y_test_shampoo = scaler.inverse_transform(testY_shampoo.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test_shape : (18, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[220.     ],\n",
       "       [230.     ],\n",
       "       [239.99998],\n",
       "       [250.     ],\n",
       "       [260.     ],\n",
       "       [270.     ],\n",
       "       [280.     ],\n",
       "       [290.     ],\n",
       "       [300.     ],\n",
       "       [310.     ],\n",
       "       [320.     ],\n",
       "       [330.     ],\n",
       "       [340.     ],\n",
       "       [350.     ],\n",
       "       [360.     ],\n",
       "       [370.     ],\n",
       "       [380.     ],\n",
       "       [390.     ]], dtype=float32)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"y_test_shape : {y_test_shampoo.shape}\")\n",
    "y_test_shampoo      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test_pred_shape : (18, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[289.69675],\n",
       "       [289.72968],\n",
       "       [289.7661 ],\n",
       "       [289.8059 ],\n",
       "       [289.84912],\n",
       "       [289.8956 ],\n",
       "       [289.94525],\n",
       "       [289.99792],\n",
       "       [290.05356],\n",
       "       [290.11194],\n",
       "       [290.17294],\n",
       "       [290.2364 ],\n",
       "       [290.3021 ],\n",
       "       [290.3699 ],\n",
       "       [290.4395 ],\n",
       "       [290.51077],\n",
       "       [290.58347],\n",
       "       [290.6573 ]], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"y_test_pred_shape : {y_test_pred_shampoo.shape}\")\n",
    "y_test_pred_shampoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 57.68 RMSE\n",
      "Test Score: 57.68 RMSE\n"
     ]
    }
   ],
   "source": [
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(y_train[:,0], y_train_pred[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(y_test[:,0], y_test_pred[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
